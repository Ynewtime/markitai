(2026-01-06-markit) ➜  2026-01-06-markit git:(main) ✗ markit convert input/file_example_PPT_250kB.ppt --llm --llm-provider gemini --verbose --analyze-image-with-md
2026-01-08T01:38:28.345795Z [info] Logs will be saved to          log_file=logs/markit.log
2026-01-08T01:38:28.346484Z [info] Starting conversion            analyze_image=True analyze_image_with_md=True input_file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt llm_enabled=True output_dir=output
2026-01-08T01:38:28.346797Z [debug] Using selector: EpollSelector 
2026-01-08T01:38:28.346971Z [info] Starting conversion pipeline   file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt output_dir=output
2026-01-08T01:38:28.347059Z [debug] Routing file                   extension=.ppt file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:38:28.347150Z [debug] Using Office preprocessor for legacy format extension=.ppt file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:38:28.347217Z [debug] Conversion plan                fallback=pandoc primary=markitdown
2026-01-08T01:38:28.347298Z [debug] Running pre-processor          processor=office_preprocessor
2026-01-08T01:38:28.347359Z [info] Converting legacy Office format file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt from_format=.ppt to_format=.pptx
2026-01-08T01:38:28.347468Z [info] Using LibreOffice for conversion
2026-01-08T01:38:28.351521Z [debug] Running LibreOffice            command='/usr/bin/soffice --headless -env:UserInstallation=file:///tmp/tmpaud3259f --convert-to pptx --outdir /tmp/tmpv43hja6k /home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt'
2026-01-08T01:38:36.510968Z [info] Legacy format converted        converted=output/converted/file_example_PPT_250kB.pptx original=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:38:36.511211Z [debug] Trying primary converter       converter=markitdown
2026-01-08T01:38:36.511331Z [info] Converting with MarkItDown     file=output/converted/file_example_PPT_250kB.pptx
2026-01-08T01:38:37.575765Z [info] Filtered PPTX footer patterns  file=output/converted/file_example_PPT_250kB.pptx patterns=['<footer>', '<number>', '<date/time>']
2026-01-08T01:38:37.576750Z [info] Applying LLM enhancement      
2026-01-08T01:38:37.600771Z [info] Enhancing Markdown             file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:38:37.906178Z [warning] LLM enhancement failed, returning original error="'Could not automatically map gpt-5.2 to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'"
2026-01-08T01:38:37.907898Z [info] Output written                 path=output/file_example_PPT_250kB.ppt.md
Conversion completed!
  Output: output/file_example_PPT_250kB.ppt.md
(2026-01-06-markit) ➜  2026-01-06-markit git:(main) ✗ markit convert input/file_example_PPT_250kB.ppt --llm --verbose --analyze-image-with-md 
2026-01-08T01:40:22.335366Z [info] Logs will be saved to          log_file=logs/markit.log
2026-01-08T01:40:22.335795Z [info] Starting conversion            analyze_image=True analyze_image_with_md=True input_file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt llm_enabled=True output_dir=output
2026-01-08T01:40:22.336092Z [debug] Using selector: EpollSelector 
2026-01-08T01:40:22.336263Z [info] Starting conversion pipeline   file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt output_dir=output
2026-01-08T01:40:22.336368Z [debug] Routing file                   extension=.ppt file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:40:22.336435Z [debug] Using Office preprocessor for legacy format extension=.ppt file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:40:22.336491Z [debug] Conversion plan                fallback=pandoc primary=markitdown
2026-01-08T01:40:22.336546Z [debug] Running pre-processor          processor=office_preprocessor
2026-01-08T01:40:22.336597Z [info] Converting legacy Office format file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt from_format=.ppt to_format=.pptx
2026-01-08T01:40:22.336694Z [info] Using LibreOffice for conversion
2026-01-08T01:40:22.340434Z [debug] Running LibreOffice            command='/usr/bin/soffice --headless -env:UserInstallation=file:///tmp/tmp2ryifevv --convert-to pptx --outdir /tmp/tmp9iuj2h04 /home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt'
2026-01-08T01:40:31.228270Z [info] Legacy format converted        converted=output/converted/file_example_PPT_250kB.pptx original=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:40:31.228652Z [debug] Trying primary converter       converter=markitdown
2026-01-08T01:40:31.228909Z [info] Converting with MarkItDown     file=output/converted/file_example_PPT_250kB.pptx
2026-01-08T01:40:32.294774Z [info] Filtered PPTX footer patterns  file=output/converted/file_example_PPT_250kB.pptx patterns=['<footer>', '<date/time>', '<number>']
2026-01-08T01:40:32.295547Z [info] Applying LLM enhancement      
2026-01-08T01:40:32.321847Z [info] Enhancing Markdown             file=/home/tseng/src/tries/2026-01-06-markit/input/file_example_PPT_250kB.ppt
2026-01-08T01:40:32.606199Z [warning] LLM enhancement failed, returning original error="'Could not automatically map gpt-5.2 to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'"
2026-01-08T01:40:32.608225Z [info] Output written                 path=output/file_example_PPT_250kB.ppt_1.md
Conversion completed!
  Output: output/file_example_PPT_250kB.ppt_1.md
(2026-01-06-markit) ➜  2026-01-06-markit git:(main) ✗ markit convert input/file-sample_100kB.doc --llm --verbose --analyze-image-with-md
2026-01-08T01:41:24.454818Z [info] Logs will be saved to          log_file=logs/markit.log
2026-01-08T01:41:24.455034Z [info] Starting conversion            analyze_image=True analyze_image_with_md=True input_file=/home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc llm_enabled=True output_dir=output
2026-01-08T01:41:24.455331Z [debug] Using selector: EpollSelector 
2026-01-08T01:41:24.455500Z [info] Starting conversion pipeline   file=/home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc output_dir=output
2026-01-08T01:41:24.455631Z [debug] Routing file                   extension=.doc file=/home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc
2026-01-08T01:41:24.455700Z [debug] Using Office preprocessor for legacy format extension=.doc file=/home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc
2026-01-08T01:41:24.455757Z [debug] Conversion plan                fallback=pandoc primary=markitdown
2026-01-08T01:41:24.455814Z [debug] Running pre-processor          processor=office_preprocessor
2026-01-08T01:41:24.455884Z [info] Converting legacy Office format file=/home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc from_format=.doc to_format=.docx
2026-01-08T01:41:24.456012Z [info] Using LibreOffice for conversion
2026-01-08T01:41:24.458996Z [debug] Running LibreOffice            command='/usr/bin/soffice --headless -env:UserInstallation=file:///tmp/tmpekoufs38 --convert-to docx --outdir /tmp/tmpcv2xu6di /home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc'
2026-01-08T01:41:30.146848Z [info] Legacy format converted        converted=output/converted/file-sample_100kB.docx original=/home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc
2026-01-08T01:41:30.147108Z [debug] Trying primary converter       converter=markitdown
2026-01-08T01:41:30.147256Z [info] Converting with MarkItDown     file=output/converted/file-sample_100kB.docx
2026-01-08T01:41:30.769118Z [info] Processing images              count=1
2026-01-08T01:41:30.947587Z [info] Image compressed               compressed_size=46239 filename=file-sample_100kB_001.jpeg original_size=63662 savings=27.4%
2026-01-08T01:41:30.947812Z [debug] Image compressed               filename=file-sample_100kB_001.jpeg savings=27.4%
2026-01-08T01:41:30.947917Z [info] Analyzing image with LLM       filename=file-sample_100kB_001.jpeg
2026-01-08T01:41:31.315820Z [info] AFC is enabled with max remote calls: 10.
2026-01-08T01:41:31.316773Z [debug] connect_tcp.started host='127.0.0.1' port=7897 local_address=None timeout=None socket_options=None
2026-01-08T01:41:31.317901Z [debug] connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x789f639c5be0>
2026-01-08T01:41:31.318082Z [debug] send_request_headers.started request=<Request [b'CONNECT']>
2026-01-08T01:41:31.318252Z [debug] send_request_headers.complete 
2026-01-08T01:41:31.318371Z [debug] send_request_body.started request=<Request [b'CONNECT']>
2026-01-08T01:41:31.318481Z [debug] send_request_body.complete    
2026-01-08T01:41:31.318547Z [debug] receive_response_headers.started request=<Request [b'CONNECT']>
2026-01-08T01:41:31.318769Z [debug] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2026-01-08T01:41:31.318857Z [debug] start_tls.started ssl_context=<ssl.SSLContext object at 0x789f7ca5efd0> server_hostname='generativelanguage.googleapis.com' timeout=None
2026-01-08T01:41:31.451135Z [debug] start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x789f639c8690>
2026-01-08T01:41:31.451442Z [debug] send_request_headers.started request=<Request [b'POST']>
2026-01-08T01:41:31.451644Z [debug] send_request_headers.complete 
2026-01-08T01:41:31.451721Z [debug] send_request_body.started request=<Request [b'POST']>
2026-01-08T01:41:31.451870Z [debug] send_request_body.complete    
2026-01-08T01:41:31.451923Z [debug] receive_response_headers.started request=<Request [b'POST']>
2026-01-08T01:41:32.850201Z [debug] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 01:41:32 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=1322'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08T01:41:32.850806Z [info] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-08T01:41:32.850983Z [debug] receive_response_body.started request=<Request [b'POST']>
2026-01-08T01:41:32.851518Z [debug] receive_response_body.complete
2026-01-08T01:41:32.851626Z [debug] response_closed.started       
2026-01-08T01:41:32.851732Z [debug] response_closed.complete      
2026-01-08T01:41:32.852321Z [info] Provider gemini initialized successfully
2026-01-08T01:41:33.258700Z [debug] Request options: {'method': 'get', 'url': '/models', 'post_parser': <function AsyncPaginator._get_page.<locals>._parser at 0x789f639a3380>, 'json_data': None}
2026-01-08T01:41:33.259051Z [debug] Sending HTTP Request: GET https://openrouter.ai/api/v1/models
2026-01-08T01:41:33.259356Z [debug] connect_tcp.started host='127.0.0.1' port=7897 local_address=None timeout=60 socket_options=None
2026-01-08T01:41:33.260329Z [debug] connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x789f62e8e710>
2026-01-08T01:41:33.260528Z [debug] send_request_headers.started request=<Request [b'CONNECT']>
2026-01-08T01:41:33.260710Z [debug] send_request_headers.complete 
2026-01-08T01:41:33.260769Z [debug] send_request_body.started request=<Request [b'CONNECT']>
2026-01-08T01:41:33.260849Z [debug] send_request_body.complete    
2026-01-08T01:41:33.260948Z [debug] receive_response_headers.started request=<Request [b'CONNECT']>
2026-01-08T01:41:33.261275Z [debug] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'Connection established', [])
2026-01-08T01:41:33.261377Z [debug] start_tls.started ssl_context=<ssl.SSLContext object at 0x789f63262490> server_hostname='openrouter.ai' timeout=60
2026-01-08T01:41:33.392560Z [debug] start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x789f632836f0>
2026-01-08T01:41:33.393115Z [debug] send_request_headers.started request=<Request [b'GET']>
2026-01-08T01:41:33.393512Z [debug] send_request_headers.complete 
2026-01-08T01:41:33.393611Z [debug] send_request_body.started request=<Request [b'GET']>
2026-01-08T01:41:33.393801Z [debug] send_request_body.complete    
2026-01-08T01:41:33.393896Z [debug] receive_response_headers.started request=<Request [b'GET']>
2026-01-08T01:41:33.491319Z [debug] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Thu, 08 Jan 2026 01:41:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'Content-Encoding', b'gzip'), (b'Access-Control-Allow-Origin', b'*'), (b'Cache-Control', b'private, no-store'), (b'Vary', b'Accept-Encoding'), (b'Permissions-Policy', b'payment=(self "https://checkout.stripe.com" "https://connect-js.stripe.com" "https://js.stripe.com" "https://*.js.stripe.com" "https://hooks.stripe.com")'), (b'Referrer-Policy', b'no-referrer, strict-origin-when-cross-origin'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'9ba7fe4389d7a439-SIN')])
2026-01-08T01:41:33.491904Z [info] HTTP Request: GET https://openrouter.ai/api/v1/models "HTTP/1.1 200 OK"
2026-01-08T01:41:33.492192Z [debug] receive_response_body.started request=<Request [b'GET']>
2026-01-08T01:41:33.569009Z [debug] receive_response_body.complete
2026-01-08T01:41:33.569194Z [debug] response_closed.started       
2026-01-08T01:41:33.569281Z [debug] response_closed.complete      
2026-01-08T01:41:33.569787Z [debug] HTTP Response: GET https://openrouter.ai/api/v1/models "200 OK" Headers({'date': 'Thu, 08 Jan 2026 01:41:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'content-encoding': 'gzip', 'access-control-allow-origin': '*', 'cache-control': 'private, no-store', 'vary': 'Accept-Encoding', 'permissions-policy': 'payment=(self "https://checkout.stripe.com" "https://connect-js.stripe.com" "https://js.stripe.com" "https://*.js.stripe.com" "https://hooks.stripe.com")', 'referrer-policy': 'no-referrer, strict-origin-when-cross-origin', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '9ba7fe4389d7a439-SIN'})
2026-01-08T01:41:33.569890Z [debug] request_id: None              
2026-01-08T01:41:33.580457Z [info] Provider openrouter initialized successfully
2026-01-08T01:41:33.580691Z [debug] Trying image analysis with provider: gemini
2026-01-08T01:41:33.580853Z [info] AFC is enabled with max remote calls: 10.
2026-01-08T01:41:33.582329Z [debug] send_request_headers.started request=<Request [b'POST']>
2026-01-08T01:41:33.582611Z [debug] send_request_headers.complete 
2026-01-08T01:41:33.582831Z [debug] send_request_body.started request=<Request [b'POST']>
2026-01-08T01:41:33.583212Z [debug] send_request_body.complete    
2026-01-08T01:41:33.583283Z [debug] receive_response_headers.started request=<Request [b'POST']>
2026-01-08T01:41:39.442310Z [debug] receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Content-Type', b'application/json; charset=UTF-8'), (b'Vary', b'Origin'), (b'Vary', b'X-Origin'), (b'Vary', b'Referer'), (b'Content-Encoding', b'gzip'), (b'Date', b'Thu, 08 Jan 2026 01:41:39 GMT'), (b'Server', b'scaffolding on HTTPServer2'), (b'X-XSS-Protection', b'0'), (b'X-Frame-Options', b'SAMEORIGIN'), (b'X-Content-Type-Options', b'nosniff'), (b'Server-Timing', b'gfet4t7; dur=5783'), (b'Alt-Svc', b'h3=":443"; ma=2592000,h3-29=":443"; ma=2592000'), (b'Transfer-Encoding', b'chunked')])
2026-01-08T01:41:39.442890Z [info] HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-3-flash-preview:generateContent "HTTP/1.1 200 OK"
2026-01-08T01:41:39.443164Z [debug] receive_response_body.started request=<Request [b'POST']>
2026-01-08T01:41:39.443944Z [debug] receive_response_body.complete
2026-01-08T01:41:39.444141Z [debug] response_closed.started       
2026-01-08T01:41:39.444302Z [debug] response_closed.complete      
2026-01-08T01:41:39.445211Z [debug] Image analysis complete        filename=file-sample_100kB_001.jpeg image_type=photo
2026-01-08T01:41:39.445357Z [debug] Image analyzed                 filename=file-sample_100kB_001.jpeg type=photo
2026-01-08T01:41:39.445463Z [info] Applying LLM enhancement      
2026-01-08T01:41:39.445568Z [info] Enhancing Markdown             file=/home/tseng/src/tries/2026-01-06-markit/input/file-sample_100kB.doc
2026-01-08T01:41:39.627470Z [warning] LLM enhancement failed, returning original error="'Could not automatically map gpt-5.2 to a tokeniser. Please use `tiktoken.get_encoding` to explicitly get the tokeniser you expect.'"
2026-01-08T01:41:39.629684Z [info] Output written                 path=output/file-sample_100kB.doc.md
2026-01-08T01:41:39.632243Z [debug] Image written                  path=output/assets/file-sample_100kB_001.jpeg
2026-01-08T01:41:39.633526Z [debug] Image description written      path=output/assets/file-sample_100kB_001.jpeg.md
Conversion completed!
  Output: output/file-sample_100kB.doc.md
  Images: 1