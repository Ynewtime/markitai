#!/usr/bin/env python3
"""
Markdown æ‰¹é‡è½¬æ¢è„šæœ¬

å°†æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ä¸­çš„æ–‡æ¡£è½¬æ¢ä¸º Markdown æ ¼å¼ï¼Œå¹¶æå–å›¾ç‰‡åˆ° assets ç›®å½•
æ”¯æŒå­æ–‡ä»¶å¤¹é€’å½’å¤„ç†ï¼Œä¿æŒåŸç›®å½•ç»“æ„

æ”¯æŒæ ¼å¼: txt, doc, docx, ppt, pptx, xls, xlsx, pdf, png, jpg, html, csv, json, xml

ä½¿ç”¨æ–¹æ³•:
    # è½¬æ¢å•ä¸ªæ–‡ä»¶
    uv run convert_to_markdown.py "æ–‡ä»¶.docx"

    # è½¬æ¢æ–‡ä»¶å¤¹
    uv run convert_to_markdown.py "æ–‡ä»¶å¤¹è·¯å¾„"

    # å¯ç”¨ LLM æ ¼å¼ä¼˜åŒ–
    uv run convert_to_markdown.py -o "æ–‡ä»¶å¤¹è·¯å¾„"

    # åˆ†ææ–‡æ¡£ä¸­æå–çš„é™„ä»¶å›¾ç‰‡
    uv run convert_to_markdown.py --analyze-attachments "æ–‡ä»¶å¤¹è·¯å¾„"

    # åˆ†æç‹¬ç«‹çš„å›¾ç‰‡æ–‡ä»¶
    uv run convert_to_markdown.py --analyze-image-files "æ–‡ä»¶å¤¹è·¯å¾„"

    # æŒ‡å®šè¾“å‡ºç›®å½•
    uv run convert_to_markdown.py -out "è¾“å‡ºè·¯å¾„" "æ–‡ä»¶å¤¹è·¯å¾„"

å‘½ä»¤è¡Œå‚æ•°:
    -o, --optimize            ä½¿ç”¨ LLM ä¼˜åŒ– Markdown æ ¼å¼
    --analyze-attachments     ä½¿ç”¨ LLM åˆ†ææ–‡æ¡£ä¸­æå–çš„é™„ä»¶å›¾ç‰‡
    --analyze-image-files     ä½¿ç”¨ LLM åˆ†æç‹¬ç«‹çš„å›¾ç‰‡æ–‡ä»¶
    -out, --output            æŒ‡å®šè¾“å‡ºç›®å½•ï¼ˆé»˜è®¤åœ¨æºæ–‡ä»¶åŒçº§æˆ–çˆ¶çº§åˆ›å»º outputï¼‰
    -h, --help                æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯

è¯´æ˜:
    - é»˜è®¤ä¸ä½¿ç”¨ LLM å¤„ç†å›¾ç‰‡
    - ç›´æ¥æŒ‡å®šå›¾ç‰‡æ–‡ä»¶æ—¶ï¼Œ--analyze-image-files é»˜è®¤å¯ç”¨
    - æ‰€æœ‰é€‰é¡¹å¯ç‹¬ç«‹ä½¿ç”¨ï¼Œä¹Ÿå¯ç»„åˆä½¿ç”¨

LLM é…ç½®ï¼ˆå¯é€‰ï¼Œç”¨äºæ ¼å¼ä¼˜åŒ–å’Œå›¾ç‰‡åˆ†æï¼‰:
    è®¾ç½®ç¯å¢ƒå˜é‡:
    - OPENAI_API_KEY + OPENAI_MODEL: OpenAI
    - OPENAI_API_KEY + OPENAI_BASE_URL + OPENAI_MODEL: OpenRouter ç­‰å…¼å®¹æ¥å£
    - GOOGLE_API_KEY: Google Gemini
    - OLLAMA_MODEL: æœ¬åœ° Ollama
    - LLM_PROMPT: è‡ªå®šä¹‰å›¾ç‰‡æè¿°æç¤ºè¯
    - LLM_CHUNK_SIZE: è¶…é•¿æ–‡æœ¬è·³è¿‡ä¼˜åŒ–çš„é˜ˆå€¼ï¼ˆé»˜è®¤ 10000 å­—ç¬¦ï¼‰
    - MAX_WORKERS: æ–‡ä»¶å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ 10ï¼‰
    - MAX_IMG_WORKERS: å•æ–‡ä»¶å†…å›¾ç‰‡å¹¶è¡Œåˆ†æçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ 5ï¼‰
    - OUTPUT_DIR: é»˜è®¤è¾“å‡ºç›®å½•

è¾“å‡ºç»“æ„ï¼ˆæ–‡ä»¶å¤¹æ¨¡å¼ï¼‰:
    è¾“å…¥: docs/my_data/
    è¾“å‡º: docs/output/      # é»˜è®¤åœ¨çˆ¶ç›®å½•åˆ›å»º output
    â”œâ”€â”€ æ–‡ä»¶å.md
    â”œâ”€â”€ assets/
    â”‚   â””â”€â”€ æ–‡ä»¶å_001.png
    â””â”€â”€ å­æ–‡ä»¶å¤¹/           # ä¿æŒåŸç›®å½•ç»“æ„
        â””â”€â”€ æ–‡ä»¶å.md
"""

import base64
import concurrent.futures
import contextlib
import datetime
import io
import json
import logging
import os
import re
import shutil
import subprocess
import sys
import threading
import time
import uuid
from functools import lru_cache
from pathlib import Path

from markitdown import MarkItDown

# ============================================================
# é¢„ç¼–è¯‘æ­£åˆ™è¡¨è¾¾å¼ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
# ============================================================
# Markdown å›¾ç‰‡å¼•ç”¨: ![alt](path)
RE_IMAGE_REF = re.compile(r"!\[([^\]]*)\]\(([^)]+)\)")
# Base64 å†…åµŒå›¾ç‰‡: ![alt](data:image/xxx;base64,...)
RE_BASE64_IMAGE = re.compile(r"!\[([^\]]*)\]\(data:image/([^;]+);base64,([^)]+)\)")
# æ–‡ä»¶åæ¸…ç†: ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
RE_SANITIZE_CHARS = re.compile(r"[\s\(\)\[\]\{\}<>\'\"#%&!@\^\*\+\=\|\\:;,\?]+")
# è¿ç»­ä¸‹åˆ’çº¿
RE_MULTI_UNDERSCORE = re.compile(r"_+")
# è¿ç»­ç©ºç™½å­—ç¬¦
RE_MULTI_WHITESPACE = re.compile(r"\s+")

# ============================================================
# æ—¥å¿—é…ç½®
# ============================================================
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%H:%M:%S",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger("converter")

# å…¨å±€äº’æ–¥é”
office_lock = threading.Lock()  # ç”¨äºä¿æŠ¤ COM å¯¹è±¡
counter_lock = threading.Lock()  # ç”¨äºä¿æŠ¤è¿›åº¦è®¡æ•°å™¨
# å…¨å±€è®¡æ•°å™¨
processed_count = 0
total_count = 0


def load_env_file():
    """ä» .env æ–‡ä»¶åŠ è½½ç¯å¢ƒå˜é‡"""
    script_dir = Path(__file__).parent
    env_file = script_dir / ".env"

    if not env_file.exists():
        return

    with open(env_file, encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            if "=" in line:
                key, _, value = line.partition("=")
                key = key.strip()
                value = value.strip().strip('"').strip("'")
                if key and value:
                    os.environ.setdefault(key, value)


# åŠ è½½ .env æ–‡ä»¶
load_env_file()

# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
SUPPORTED_FORMATS = {
    # æ–‡æ¡£
    ".txt",
    ".doc",
    ".docx",
    ".ppt",
    ".pptx",
    ".xls",
    ".xlsx",
    ".pdf",
    # å›¾ç‰‡ï¼ˆéœ€è¦ LLM æ‰èƒ½ç”Ÿæˆæè¿°ï¼‰
    ".png",
    ".jpg",
    ".jpeg",
    ".gif",
    ".webp",
    ".bmp",
    # å…¶ä»–
    ".html",
    ".htm",
    ".csv",
    ".json",
    ".xml",
}
# éœ€è¦å…ˆè½¬æ¢çš„æ—§æ ¼å¼
OLD_FORMATS = {".doc": ".docx", ".ppt": ".pptx"}
# å›¾ç‰‡æ ¼å¼
IMAGE_FORMATS = {".png", ".jpg", ".jpeg", ".gif", ".webp", ".bmp"}
# PPTX æ ¼å¼ï¼ˆå«åµŒå…¥å›¾ç‰‡ï¼Œå¯é€‰ LLM åˆ†æï¼‰
PPTX_FORMATS = {".pptx"}

# LLM å†…å®¹æè¿°æç¤ºè¯ï¼ˆç”¨äºå›¾ç‰‡/PPT/PDFç­‰ï¼‰
LLM_CONTENT_PROMPT = """è¯·ç”¨ä¸­æ–‡å¯¹è¿™ä¸ªå†…å®¹è¿›è¡Œå®Œæ•´ã€ç»“æ„åŒ–çš„æè¿°ï¼Œè¾“å‡ºå¹²å‡€çš„ Markdown æ ¼å¼ã€‚

## è¾“å‡ºè¦æ±‚

æ ¹æ®å†…å®¹ç±»å‹ï¼ŒæŒ‰ä»¥ä¸‹è§„èŒƒæè¿°ï¼š

### ğŸ“Š å¦‚æœæ˜¯å›¾è¡¨/æ•°æ®å¯è§†åŒ–
- å›¾è¡¨ç±»å‹ï¼ˆæŸ±çŠ¶å›¾/æŠ˜çº¿å›¾/é¥¼å›¾/æµç¨‹å›¾ç­‰ï¼‰
- æ ‡é¢˜å’Œä¸»é¢˜
- åæ ‡è½´/å›¾ä¾‹è¯´æ˜
- å…³é”®æ•°æ®ç‚¹å’Œæ•°å€¼ï¼ˆå°½å¯èƒ½æå–å…·ä½“æ•°å­—ï¼‰
- æ•°æ®è¶‹åŠ¿å’Œç»“è®º

### ğŸ–¼ï¸ å¦‚æœæ˜¯æ™®é€šå›¾ç‰‡/ç…§ç‰‡
- ä¸»ä½“å†…å®¹å’Œåœºæ™¯æè¿°
- é‡è¦çš„æ–‡å­—ä¿¡æ¯ï¼ˆå®Œæ•´æå–ï¼‰
- é¢œè‰²ã€æ„å›¾ã€é£æ ¼ç‰¹ç‚¹
- å›¾ç‰‡å¯èƒ½çš„ç”¨é€”å’Œä¸Šä¸‹æ–‡

### ğŸ“‘ å¦‚æœæ˜¯æ–‡æ¡£/PPTé¡µé¢
- æ ‡é¢˜å’Œç« èŠ‚ç»“æ„
- å®Œæ•´æå–æ‰€æœ‰æ–‡å­—å†…å®¹ï¼ˆä¸è¦é—æ¼ï¼‰
- è¦ç‚¹åˆ—è¡¨å’Œå±‚çº§å…³ç³»
- è¡¨æ ¼æ•°æ®ï¼ˆè½¬ä¸º Markdown è¡¨æ ¼ï¼‰
- å›¾è¡¨å’Œå›¾ç‰‡çš„æè¿°

### ğŸ“ å¦‚æœæ˜¯æŠ€æœ¯å›¾/æ¶æ„å›¾/æµç¨‹å›¾
- å›¾çš„ç±»å‹å’Œæ•´ä½“ç»“æ„
- å„ç»„ä»¶/èŠ‚ç‚¹çš„åç§°å’Œå«ä¹‰
- è¿æ¥å…³ç³»å’Œæ•°æ®æµå‘
- å…³é”®æ­¥éª¤å’Œé€»è¾‘

## æ ¼å¼è§„èŒƒ

- ä½¿ç”¨æ¸…æ™°çš„ Markdown ç»“æ„ï¼ˆæ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ï¼‰
- æ ‡é¢˜ä» ## å¼€å§‹ï¼Œä¸ä½¿ç”¨ #
- æ•°å­—å’Œä¸“æœ‰åè¯ä¿æŒåŸæ ·
- æå–çš„æ–‡å­—ç”¨ > å¼•ç”¨å—æ ‡æ³¨
- é‡è¦ä¿¡æ¯ç”¨ **åŠ ç²—** æ ‡æ³¨

## æ ¸å¿ƒåŸåˆ™

1. **å®Œæ•´æ€§**ï¼šæå–æ‰€æœ‰å¯è§çš„æ–‡å­—å’Œæ•°æ®ï¼Œä¸è¦çœç•¥
2. **å‡†ç¡®æ€§**ï¼šå¦‚å®æè¿°ï¼Œä¸è¦æ¨æµ‹ä¸ç¡®å®šçš„å†…å®¹
3. **ç»“æ„åŒ–**ï¼šç”¨åˆé€‚çš„ Markdown æ ¼å¼ç»„ç»‡ä¿¡æ¯
4. **å®ç”¨æ€§**ï¼šæè¿°åº”ä¾¿äºåç»­æ£€ç´¢å’Œç†è§£"""

# æ ¼å¼ä¼˜åŒ–æç¤ºè¯ï¼ˆä½¿ç”¨ {{PLACEHOLDER}} å ä½ç¬¦ï¼‰
FORMAT_OPTIMIZE_PROMPT = """## ä»»åŠ¡

å°†æ–‡ä»¶ä¼˜åŒ–ä¸ºé«˜è´¨é‡çš„ Markdown æ ¼å¼ã€‚

## è¾“å‡ºè¦æ±‚

- åœ¨å¤´éƒ¨æ·»åŠ  YAML Frontmatterï¼Œå¿…é¡»ä½¿ç”¨ `---` åŒ…è£¹ï¼ˆä¸¥ç¦ä½¿ç”¨ ```yaml ä»£ç å—åŒ…è£¹ï¼‰
- YAML Frontmatter å†…å®¹ç´§è·Ÿ `---` åçš„ä¸‹ä¸€è¡Œï¼Œä¸è¦æœ‰ç©ºè¡Œ
- YAML Frontmatter åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
  - title: {{TITLE_INSTRUCTION}}
  - processed: {{PROCESSED_DATE}}
  - author: ä½œè€…ï¼ˆå¦‚æœèƒ½è¯†åˆ«ï¼Œå¦åˆ™ç•™ç©ºï¼‰
  - description: æ–‡æ¡£å†…å®¹æ‘˜è¦ï¼ˆå¦‚æœåŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œè¯·ä½¿ç”¨åŒå¼•å·åŒ…è£¹ï¼‰
- ç¬¦åˆ Obsidian Flavored Markdown / GFM è§„èŒƒ

---

## æ ¸å¿ƒåŸåˆ™

ä»…åšæ ¼å¼è½¬æ¢ï¼Œä¸¥ç¦ä¿®æ”¹ä»»ä½•åŸæ–‡å†…å®¹ï¼ä¸è¦æ€»ç»“ã€æç‚¼æˆ–æ”¹å†™æ–‡æ¡ˆï¼
å°½æœ€å¤§ç¨‹åº¦ä¿ç•™å†…å®¹ï¼Œå¯¹äºé•¿æ–‡æœ¬ä¹Ÿä¸è¦çœç•¥å†…å®¹ï¼Œä¸è¦åˆ»æ„åˆ å‡å†…å®¹

---

## æ¸…æ´—è§„èŒƒ (Cleaning Rules)

1. **é¡µçœ‰é¡µè„š**
   - åˆ é™¤é‡å¤å‡ºç°çš„é¡µçœ‰é¡µè„šå†…å®¹ï¼Œå¦‚ `Page 1 of 10`
   - åˆ é™¤å…¬å¸æœºå¯†å£°æ˜ï¼Œå¦‚ `Confidential`, `Internal Use Only` ç­‰ï¼ˆå¦‚æœå®ƒä»¬ä½œä¸ºé¡µè„šåå¤å‡ºç°ï¼‰
   - åˆ é™¤æ— æ„ä¹‰çš„åˆ†éš”ç¬¦æˆ–ä¹±ç 

2. **ç©ºè¡Œä¸é—´è·**
   - Header ä¸ Header ä¹‹é—´ä¿ç•™ä¸€ä¸ªç©ºè¡Œ
   - Header ä¸æ­£æ–‡ä¹‹é—´ä¿ç•™ä¸€ä¸ªç©ºè¡Œ
   - è¿ç»­çš„ <br/> æˆ–ç©ºè¡Œåˆå¹¶ä¸ºä¸€ä¸ªç©ºè¡Œ

## æ ¼å¼è§„èŒƒ

1. æ ‡é¢˜
   - ä¸è¦è‡ªè¡Œæ·»åŠ æ ‡é¢˜å±‚çº§
   - æ ‡é¢˜å±‚çº§ä» h2 å¼€å§‹ï¼Œä¸è¦ä½¿ç”¨ h1 (h1é€šå¸¸ä½œä¸ºæ–‡ä»¶å/title)

2. é“¾æ¥ä¸å›¾ç‰‡
   - é“¾æ¥ï¼š[text](href)
   - å›¾ç‰‡ï¼š![alt](src)

3. åˆ—è¡¨å¤„ç†
   - æœ‰åºåˆ—è¡¨ï¼šä¿ç•™æ•°å­—åºåˆ—ï¼Œå¦‚ 1. é¡¹ç›®
   - æ— åºåˆ—è¡¨ï¼šä½¿ç”¨ - æˆ– *ï¼Œå¦‚ - é¡¹ç›®
   - åµŒå¥—åˆ—è¡¨ï¼šé€šè¿‡ç¼©è¿›è¡¨ç¤ºå±‚çº§

4. æ–‡æœ¬æ ·å¼
   - åŠ ç²—ï¼š**text**ï¼ˆå¤„ç†è§„åˆ™è§åæ–‡åŠ ç²—æ–‡æœ¬éƒ¨åˆ†ï¼‰
   - æ–œä½“ï¼š*text* æˆ– _text_
   - åˆ é™¤çº¿ï¼š~~text~~
   - å†…è”ä»£ç ï¼š`code`
   - ä¸Šæ ‡ï¼š^text^
   - ä¸‹æ ‡ï¼š~text~

5. å¼•ç”¨å—
   - ä½¿ç”¨ > è¡¨ç¤ºï¼Œå¤šå±‚å¼•ç”¨ä½¿ç”¨ >>>
   - ç¤ºä¾‹ï¼š<blockquote>å¼•ç”¨</blockquote> -> > å¼•ç”¨

6. ä»£ç å—
   - æ ‡æ³¨æ­£ç¡®çš„è¯­è¨€æ ‡è¯†
   - ä¿æŒä»£ç åŸæ ·ï¼Œä¸æ·»åŠ æ— å…³å­—ç¬¦
   - åµŒå¥—è§„åˆ™ï¼šå¤–å±‚ä»£ç å—çš„åå¼•å·æ•°é‡ = å†…å±‚æœ€å¤§åå¼•å·æ•° + 1

7. è¡¨æ ¼
   - ä½¿ç”¨ | åˆ†éš”åˆ—ï¼Œ- åˆ†éš”è¡¨å¤´ä¸å†…å®¹
   - ç¤ºä¾‹ï¼šHTML è¡¨æ ¼è½¬æ¢ä¸º | åˆ—1 | åˆ—2 | å’Œ | --- | --- |

8. åˆ†éš”çº¿
   - ä½¿ç”¨ --- æˆ– *** è¡¨ç¤º

9. ä»»åŠ¡åˆ—è¡¨
   - ä½¿ç”¨ - [ ] å’Œ - [x] è¡¨ç¤ºæœªå®Œæˆå’Œå·²å®Œæˆä»»åŠ¡

10. è„šæ³¨
    - ä½¿ç”¨ [^1] æ ‡æ³¨ï¼Œå¹¶åœ¨æ–‡æœ«å®šä¹‰ [^1]: æ³¨é‡Šå†…å®¹

11. å¤šåª’ä½“
    - ä¸æ”¯æŒ Markdown çš„å¤šåª’ä½“å†…å®¹å¯ä¿ç•™ HTML ä»£ç 
    - å…¶ä»–å†…å®¹ä¸€å¾‹ä½¿ç”¨ Markdown è¯­æ³•

12. åŠ ç²—æ–‡æœ¬
    - è¿ç»­çš„ <strong> æ ‡ç­¾åˆå¹¶ä¸ºå•ä¸ª **text**
    - æ ‡ç‚¹ä½ç½®ä¿®æ­£ï¼šã€‚** -> **ã€‚ï¼Œï¼Œ** -> **ï¼Œï¼Œï¼š** -> **ï¼šï¼ˆé‡è¦ï¼åŠ ç²—çš„åŒæ˜Ÿå·è¦ç§»åˆ°æ ‡ç‚¹ç¬¦å·å¤–ï¼‰

---

## å¾…ä¼˜åŒ–çš„ Markdown å†…å®¹

"""


def create_llm_client():
    """
    æ ¹æ®ç¯å¢ƒå˜é‡åˆ›å»º LLM å®¢æˆ·ç«¯
    æ”¯æŒ: OpenAI, OpenRouter, Google Gemini, Azure OpenAI, Ollama, è‡ªå®šä¹‰æ¥å£

    ä¼˜å…ˆçº§:
    1. OPENAI_API_BASE/OPENAI_BASE_URL (è‡ªå®šä¹‰æ¥å£ï¼ŒåŒ…æ‹¬ OpenRouter)
    2. GOOGLE_API_KEY / GEMINI_API_KEY (Google Gemini)
    3. AZURE_OPENAI_* (Azure OpenAI)
    4. OPENAI_API_KEY (åŸç”Ÿ OpenAI)
    5. OLLAMA_MODEL (æœ¬åœ° Ollama)
    """
    try:
        from openai import AzureOpenAI, OpenAI
    except ImportError:
        logger.warning("âš ï¸ æœªå®‰è£… openai åŒ…ï¼ŒLLM åŠŸèƒ½ä¸å¯ç”¨")
        logger.warning("   è¿è¡Œ: uv add openai")
        return None, None

    # 1. è‡ªå®šä¹‰ OpenAI å…¼å®¹æ¥å£ï¼ˆOpenRouter ç­‰ï¼‰
    api_base = os.environ.get("OPENAI_API_BASE") or os.environ.get("OPENAI_BASE_URL")
    if api_base:
        api_key = os.environ.get("OPENAI_API_KEY")
        model = os.environ.get("OPENAI_MODEL") or os.environ.get("LLM_MODEL", "gpt-4o")
        if api_key:
            client = OpenAI(api_key=api_key, base_url=api_base)
            provider = "OpenRouter" if "openrouter" in api_base.lower() else "è‡ªå®šä¹‰æ¥å£"
            logger.info(f"âœ… å·²å¯ç”¨ {provider} LLM: {model}")
            return client, model

    # 2. Google Geminiï¼ˆé€šè¿‡ OpenAI å…¼å®¹æ¥å£ï¼‰
    gemini_key = os.environ.get("GOOGLE_API_KEY") or os.environ.get("GEMINI_API_KEY")
    if gemini_key:
        model = os.environ.get("GEMINI_MODEL", "gemini-2.0-flash")
        client = OpenAI(
            api_key=gemini_key,
            base_url="https://generativelanguage.googleapis.com/v1beta/openai/",
        )
        logger.info(f"âœ… å·²å¯ç”¨ Google Gemini LLM: {model}")
        return client, model

    # 3. Azure OpenAI
    azure_key = os.environ.get("AZURE_OPENAI_API_KEY")
    azure_endpoint = os.environ.get("AZURE_OPENAI_ENDPOINT")
    if azure_key and azure_endpoint:
        client = AzureOpenAI(
            api_key=azure_key,
            api_version=os.environ.get("AZURE_OPENAI_API_VERSION", "2024-02-01"),
            azure_endpoint=azure_endpoint,
        )
        model = os.environ.get("AZURE_OPENAI_MODEL", "gpt-4o")
        logger.info(f"âœ… å·²å¯ç”¨ Azure OpenAI LLM: {model}")
        return client, model

    # 4. åŸç”Ÿ OpenAI
    openai_key = os.environ.get("OPENAI_API_KEY")
    if openai_key:
        model = os.environ.get("OPENAI_MODEL", "gpt-4o")
        client = OpenAI(api_key=openai_key)
        logger.info(f"âœ… å·²å¯ç”¨ OpenAI LLM: {model}")
        return client, model

    # 5. æœ¬åœ° Ollama
    ollama_model = os.environ.get("OLLAMA_MODEL")
    if ollama_model:
        ollama_host = os.environ.get("OLLAMA_HOST", "http://localhost:11434")
        client = OpenAI(base_url=f"{ollama_host}/v1", api_key="ollama")
        logger.info(f"âœ… å·²å¯ç”¨ Ollama LLM: {ollama_model}")
        return client, ollama_model

    return None, None


def optimize_markdown_format(
    markdown_text: str,
    llm_client,
    llm_model: str,
    file_title: str | None = None,
    max_retries: int = 5,
    base_delay: float = 10.0,
    logger=print,
) -> str:
    """ä½¿ç”¨ LLM ä¼˜åŒ– Markdown æ ¼å¼ï¼Œå¸¦é‡è¯•æœºåˆ¶

    Args:
        markdown_text: å¾…ä¼˜åŒ–çš„ Markdown æ–‡æœ¬
        llm_client: LLM å®¢æˆ·ç«¯
        llm_model: LLM æ¨¡å‹åç§°
        file_title: æ–‡ä»¶æ ‡é¢˜ï¼ˆç”¨äº Frontmatterï¼‰
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        base_delay: é‡è¯•åŸºç¡€å»¶è¿Ÿï¼ˆç§’ï¼‰
        logger: æ—¥å¿—å‡½æ•°

    æ³¨æ„ï¼šåªå‘é€çº¯æ–‡æœ¬ç»™ LLMï¼ˆåŒ…æ‹¬ ![alt](path) è¿™æ ·çš„å›¾ç‰‡å¼•ç”¨ï¼‰ï¼Œ
    ä¸ä¼šå‘é€å®é™…çš„å›¾ç‰‡æ•°æ®ã€‚
    """
    if not llm_client or not llm_model:
        return markdown_text

    # å‡†å¤‡ Promptï¼Œä½¿ç”¨å ä½ç¬¦æ›¿æ¢
    current_prompt = FORMAT_OPTIMIZE_PROMPT

    # æ›¿æ¢ title å ä½ç¬¦
    if file_title:
        # è½¬ä¹‰åŒå¼•å·ï¼Œé˜²æ­¢ YAML è¯­æ³•é”™è¯¯
        safe_title = file_title.replace('"', '\\"')
        title_instruction = f'"{safe_title}" (è¯·ç›´æ¥ä½¿ç”¨æ­¤æ ‡é¢˜)'
    else:
        title_instruction = 'æ–‡ä»¶æ ‡é¢˜ï¼ˆä»å†…å®¹è¯†åˆ«ï¼Œå¦‚æœåŒ…å«ç‰¹æ®Šå­—ç¬¦å¦‚å†’å·ï¼Œè¯·ä½¿ç”¨åŒå¼•å·åŒ…è£¹ï¼Œä¾‹å¦‚ title: "Title: Subtitle"ï¼‰'
    current_prompt = current_prompt.replace("{{TITLE_INSTRUCTION}}", title_instruction)

    # å‡†å¤‡æ—¥æœŸå ä½ç¬¦
    current_date = datetime.datetime.now().strftime("%Y-%m-%d")
    current_prompt = current_prompt.replace("{{PROCESSED_DATE}}", current_date)

    # çŸ­æ–‡æœ¬ï¼šç›´æ¥å¤„ç†ï¼ˆä¿æŒåŸæœ‰é€»è¾‘ï¼ŒåŒ…å«æ‘˜è¦ç”Ÿæˆï¼‰
    # æ³¨æ„ï¼šæ—¥æœŸå·²åœ¨å‡½æ•°å¼€å¤´æ›¿æ¢åˆ° current_prompt ä¸­
    for attempt in range(max_retries):
        try:
            response = llm_client.chat.completions.create(
                model=llm_model,
                messages=[{"role": "user", "content": current_prompt + markdown_text}],
                temperature=0.1,  # ä½æ¸©åº¦ï¼Œä¿æŒä¸€è‡´æ€§
            )

            optimized = response.choices[0].message.content

            # æ¸…ç†å¯èƒ½çš„ markdown ä»£ç å—åŒ…è£¹
            if optimized.startswith("```markdown"):
                optimized = optimized[len("```markdown") :].strip()
            elif optimized.startswith("```md"):
                optimized = optimized[len("```md") :].strip()
            # æ³¨æ„ï¼šä¸å»ºè®®ç›´æ¥æ¸…ç† ```ï¼Œå› ä¸ºå¯èƒ½è¯¯ä¼¤æ­£æ–‡ä¸­çš„ä»£ç å—
            # ä½†å¦‚æœæ•´æ®µéƒ½æ˜¯ä»£ç å—åŒ…è£¹çš„ï¼Œåˆ™éœ€è¦æ¸…ç†
            elif optimized.startswith("```") and optimized.endswith("```"):
                optimized = optimized[3:-3].strip()

            # ä¿®å¤ï¼šç§»é™¤ Frontmatter å¼€å§‹å¤„å¤šä½™çš„ç©ºè¡Œ
            # é’ˆå¯¹ç”¨æˆ·åé¦ˆ: ---\n\ntitle: (--- å’Œ title ä¹‹é—´æœ‰ç©ºè¡Œ)
            if optimized.startswith("---"):
                # æ–¹æ³•1: ç§»é™¤ --- åçš„æ‰€æœ‰ç©ºç™½è¡Œï¼Œç›´åˆ°é‡åˆ°éç©ºè¡Œ
                lines = optimized.split("\n")
                if lines[0] == "---":
                    # æ‰¾åˆ°ç¬¬ä¸€ä¸ªéç©ºè¡Œçš„ç´¢å¼•
                    first_content_idx = 1
                    while first_content_idx < len(lines) and not lines[first_content_idx].strip():
                        first_content_idx += 1
                    # é‡ç»„: --- + éç©ºå†…å®¹
                    if first_content_idx > 1:
                        optimized = "---\n" + "\n".join(lines[first_content_idx:])

            # é¢å¤–æ£€æŸ¥ï¼šå¦‚æœå¤´éƒ¨æ˜¯ ```yaml åŒ…è£¹çš„ Frontmatterï¼Œå°è¯•ä¿®å¤
            # é”™è¯¯ç¤ºä¾‹:
            # ```yaml
            # title: ...
            # ```
            # æ­£æ–‡...
            if optimized.startswith("```yaml"):
                optimized = optimized.replace("```yaml", "---", 1)
                # å¯»æ‰¾ä¸‹ä¸€ä¸ª ``` å¹¶æ›¿æ¢ä¸º ---
                if "\n```\n" in optimized:
                    optimized = optimized.replace("\n```\n", "\n---\n", 1)
                elif "\n```" in optimized:  # å¤„ç†ç´§å‡‘æƒ…å†µ
                    optimized = optimized.replace("\n```", "\n---", 1)

            # é¢å¤–æ£€æŸ¥ï¼šYAML å†’å·è½¬ä¹‰ä¿®å¤
            # æœ‰äº›æ¨¡å‹ç”Ÿæˆ title: Something: Subtitle è€Œä¸æ˜¯ title: "Something: Subtitle"
            try:
                # æå– Frontmatter
                if optimized.startswith("---"):
                    end_idx = optimized.find("\n---", 3)
                    if end_idx != -1:
                        frontmatter = optimized[3:end_idx]
                        new_frontmatter = []
                        for line in frontmatter.splitlines():
                            # è·³è¿‡ç©ºè¡Œï¼Œé˜²æ­¢åœ¨ --- å’Œ title ä¹‹é—´äº§ç”Ÿç©ºè¡Œ
                            if not line.strip():
                                continue
                            # ç®€å•ä¿®å¤é€»è¾‘ï¼šæ£€æŸ¥å¸¸è§å­—æ®µï¼Œå¦‚æœå€¼åŒ…å«å†’å·ä¸”æœªåŠ å¼•å·ï¼Œåˆ™æ·»åŠ å¼•å·
                            if ":" in line:
                                key, _, val = line.partition(":")
                                key = key.strip()
                                val = val.strip()
                                # å¦‚æœå€¼åŒ…å«å†’å·ï¼Œä¸”æ²¡æœ‰è¢«å¼•å·åŒ…è£¹
                                if (
                                    ":" in val
                                    and not (val.startswith('"') and val.endswith('"'))
                                    and not (val.startswith("'") and val.endswith("'"))
                                ):
                                    # é’ˆå¯¹ title å’Œ description å­—æ®µ
                                    if key in ["title", "description"]:
                                        # æ›¿æ¢åŒå¼•å·ä¸ºå•å¼•å·ï¼Œé˜²æ­¢è½¬ä¹‰é—®é¢˜
                                        val_escaped = val.replace('"', '\\"')
                                        new_line = f'{key}: "{val_escaped}"'
                                        new_frontmatter.append(new_line)
                                        continue
                            new_frontmatter.append(line)

                        # é‡ç»„å†…å®¹
                        optimized = "---\n" + "\n".join(new_frontmatter) + optimized[end_idx:]
            except Exception:
                pass  # å¦‚æœè§£æå¤±è´¥ï¼Œä¿æŒåŸæ ·

            return optimized

        except Exception as e:
            error_msg = str(e)

            # æ£€æŸ¥æ˜¯å¦æ˜¯é€Ÿç‡é™åˆ¶é”™è¯¯
            is_rate_limit = any(
                x in error_msg for x in ["429", "rate", "quota", "RESOURCE_EXHAUSTED", "Too Many"]
            )

            if is_rate_limit and attempt < max_retries - 1:
                # æŒ‡æ•°é€€é¿ï¼š10s, 20s, 40s, 80s, 160s
                delay = base_delay * (2**attempt)
                logger(
                    f"      â³ API é€Ÿç‡é™åˆ¶ï¼Œ{delay:.0f}ç§’åé‡è¯• ({attempt + 1}/{max_retries})..."
                )
                time.sleep(delay)
            else:
                logger(f"      âš ï¸ æ ¼å¼ä¼˜åŒ–å¤±è´¥: {e}")
                return markdown_text

    return markdown_text


# å›¾ç‰‡åˆ†ææç¤ºè¯
IMAGE_ANALYZE_PROMPT = """è¯·åˆ†æè¿™å¼ å›¾ç‰‡çš„å†…å®¹ï¼Œå¹¶ä»¥ JSON æ ¼å¼è¿”å›ä¸¤ä»½æè¿°ã€‚

è¦æ±‚è¿”å› JSON æ ¼å¼å¦‚ä¸‹ï¼š
{
    "summary": "ä¸€å¥è¯æ€»ç»“å›¾ç‰‡å†…å®¹ï¼Œç®€æ˜æ‰¼è¦ï¼Œä¸æ¢è¡Œï¼Œä¸ä½¿ç”¨ Markdown è¯­æ³•ï¼Œç”¨äº alt å±æ€§ã€‚",
    "detail": "è¯¦ç»†æè¿°å›¾ç‰‡å†…å®¹ï¼Œè¦†ç›–æ‰€æœ‰ç»†èŠ‚ï¼ˆæ–‡å­—ã€æ•°æ®ã€é¢œè‰²ã€å¸ƒå±€ç­‰ï¼‰ã€‚ä½¿ç”¨ Markdown æ ¼å¼ï¼ˆå¯ä»¥åŒ…å«æ ‡é¢˜ã€åˆ—è¡¨ã€è¡¨æ ¼ç­‰ï¼‰ï¼Œç”¨äºå•ç‹¬çš„æ–‡æ¡£ã€‚"
}

æ³¨æ„ï¼š
1. ä»…è¿”å›åˆæ³•çš„ JSON å­—ç¬¦ä¸²ï¼Œä¸è¦åŒ…å« ```json åŒ…è£¹ã€‚
2. "summary" å­—æ®µå¿…é¡»ç®€æ´ï¼Œé€‚åˆä½œä¸ºå›¾ç‰‡çš„æ›¿ä»£æ–‡æœ¬ã€‚
3. "detail" å­—æ®µè¦å°½å¯èƒ½è¯¦ç»†ï¼Œä¸è¦é—æ¼ä¿¡æ¯ã€‚
"""


def analyze_image_with_llm(
    image_path: Path,
    llm_client,
    llm_model: str,
    max_retries: int = 5,
    base_delay: float = 10.0,
    logger=print,
) -> str | None:
    """ä½¿ç”¨ LLM åˆ†æå›¾ç‰‡ï¼Œç”Ÿæˆæè¿°æ–‡æœ¬

    Returns:
        str: å‡€åŒ–åçš„ summaryï¼ˆç”¨äº alt æ–‡æœ¬ï¼‰
    Side Effect:
        åœ¨ assets ç›®å½•ä¸‹ç”ŸæˆåŒåçš„ .md æ–‡ä»¶ï¼ŒåŒ…å« detail è¯¦ç»†æè¿°
    """
    if not llm_client or not llm_model or not image_path.exists():
        return None

    # base64, json, time å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥

    # è¯»å–å›¾ç‰‡å¹¶è½¬ä¸º base64
    try:
        image_data = image_path.read_bytes()
        base64_image = base64.b64encode(image_data).decode("utf-8")

        # æ ¹æ®æ‰©å±•åç¡®å®š MIME ç±»å‹
        ext = image_path.suffix.lower()
        mime_map = {
            ".jpg": "image/jpeg",
            ".jpeg": "image/jpeg",
            ".png": "image/png",
            ".gif": "image/gif",
            ".webp": "image/webp",
            ".bmp": "image/bmp",
        }
        mime_type = mime_map.get(ext, "image/png")

    except Exception as e:
        logger(f"        âš ï¸ è¯»å–å›¾ç‰‡å¤±è´¥: {e}")
        return None

    for attempt in range(max_retries):
        try:
            # å‡†å¤‡è¯·æ±‚å‚æ•°
            request_params = {
                "model": llm_model,
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": IMAGE_ANALYZE_PROMPT},
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:{mime_type};base64,{base64_image}"},
                            },
                        ],
                    }
                ],
                # ç§»é™¤ max_tokens é™åˆ¶ï¼Œé¿å…é•¿æè¿°æˆªæ–­å¯¼è‡´ JSON æ ¼å¼é”™è¯¯
                # "max_tokens": 2000,
            }

            # å°è¯•æ·»åŠ  response_format å‚æ•°ï¼ˆOpenAI/Azure/Ollama JSON æ¨¡å¼ï¼‰
            # æ³¨æ„ï¼šæŸäº›æ¨¡å‹/æ—§ç‰ˆ OpenAI æ¥å£å¯èƒ½ä¸æ”¯æŒæ­¤å‚æ•°ï¼Œå¦‚æœæŠ¥é”™ä¼šå›é€€
            try:
                request_params["response_format"] = {"type": "json_object"}
                response = llm_client.chat.completions.create(**request_params)
            except Exception as e:
                # å¦‚æœæ˜¯å‚æ•°é”™è¯¯ï¼ˆ400 Bad Requestï¼‰ï¼Œå°è¯•ç§»é™¤ response_format é‡è¯•
                error_str = str(e).lower()
                if (
                    "response_format" in error_str
                    or "unsupported parameter" in error_str
                    or "400" in error_str
                ):
                    # logger(f"        â„¹ï¸ æ¨¡å‹ä¸æ”¯æŒ response_formatï¼Œå°è¯•æ™®é€šæ–‡æœ¬æ¨¡å¼")
                    del request_params["response_format"]
                    response = llm_client.chat.completions.create(**request_params)
                else:
                    raise e  # å…¶ä»–é”™è¯¯ï¼ˆå¦‚ 429ï¼‰æŠ›å‡ºç»™å¤–å±‚é‡è¯•é€»è¾‘å¤„ç†

            content = response.choices[0].message.content.strip()

            # æ¸…ç†å¯èƒ½çš„ Markdown ä»£ç å—åŒ…è£¹
            if content.startswith("```json"):
                content = content[7:]
            elif content.startswith("```"):
                content = content[3:]
            if content.endswith("```"):
                content = content[:-3]

            content = content.strip()

            try:
                data = json.loads(content)
                summary = data.get("summary", "")
                detail = data.get("detail", "")
            except json.JSONDecodeError:
                # é™çº§å¤„ç†ï¼šå¦‚æœä¸æ˜¯ JSONï¼Œå‡è®¾æ•´ä¸ªå†…å®¹æ˜¯ detailedï¼Œå°è¯•ç”Ÿæˆä¸€ä¸ª summary
                logger("        âš ï¸ å“åº”é JSON æ ¼å¼ï¼Œå°è¯•é™çº§å¤„ç†")
                detail = content
                summary = content[:50].replace("\n", " ") + "..."

            # 1. ä¿å­˜è¯¦ç»†æè¿°åˆ° .md æ–‡ä»¶
            if detail:
                try:
                    # ä½¿ç”¨ <å›¾ç‰‡å>.<å›¾ç‰‡åç¼€>.md æ ¼å¼
                    desc_file = image_path.with_name(f"{image_path.name}.md")
                    desc_file.write_text(detail, encoding="utf-8")
                except Exception as e:
                    logger(f"        âš ï¸ ä¿å­˜æè¿°æ–‡ä»¶å¤±è´¥: {e}")

            # 2. è¿”å› Summary ç”¨äº alt
            if summary:
                # å†æ¬¡ç¡®ä¿ summary æ— æ¢è¡Œï¼ˆä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™ï¼‰
                clean_summary = summary.replace("\n", " ").replace("\r", " ")
                clean_summary = RE_MULTI_WHITESPACE.sub(" ", clean_summary).strip()
                return clean_summary

            return None

        except Exception as e:
            error_msg = str(e)

            is_rate_limit = any(
                x in error_msg for x in ["429", "rate", "quota", "RESOURCE_EXHAUSTED", "Too Many"]
            )

            if is_rate_limit and attempt < max_retries - 1:
                delay = base_delay * (2**attempt)
                logger(
                    f"        â³ API é€Ÿç‡é™åˆ¶ï¼Œ{delay:.0f}ç§’åé‡è¯• ({attempt + 1}/{max_retries})..."
                )
                time.sleep(delay)
            else:
                logger(f"        âš ï¸ å›¾ç‰‡åˆ†æå¤±è´¥: {e}")
                return None

    return None


def analyze_images_in_markdown(
    markdown_text: str,
    assets_dir: Path,
    llm_client,
    llm_model: str,
    use_concurrency: bool = True,
    logger=logger.info,
) -> str:
    """åˆ†æ Markdown ä¸­çš„å›¾ç‰‡ï¼Œä½¿ç”¨çº¿ç¨‹æ± å¹¶è¡Œå¤„ç†

    Args:
        use_concurrency: æ˜¯å¦ä½¿ç”¨å¤šçº¿ç¨‹å¹¶è¡Œï¼ˆå½“å¤–å±‚å·²ç»å¹¶è¡Œæ—¶ï¼Œå†…å±‚å»ºè®®ä¸²è¡Œä»¥é˜² API æ´ªæ³›ï¼‰
        logger: æ—¥å¿—å‡½æ•°
    """
    if not llm_client or not llm_model:
        return markdown_text

    # åŒ¹é… ![alt](path) æ ¼å¼ï¼ˆä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™ï¼‰
    matches = list(RE_IMAGE_REF.finditer(markdown_text))

    if not matches:
        return markdown_text

    logger(f"      ğŸ” å‘ç° {len(matches)} å¼ å›¾ç‰‡ï¼Œæ­£åœ¨åˆ†æ...")

    # å‡†å¤‡ä»»åŠ¡
    tasks = []
    for match in matches:
        img_path_str = match.group(2)

        # å¤„ç†ç›¸å¯¹è·¯å¾„
        if img_path_str.startswith("assets/"):
            img_path = assets_dir.parent / img_path_str
        else:
            img_path = Path(img_path_str)

        tasks.append((match, img_path, img_path_str))

    replacements = []

    # å†³å®šæ˜¯å¦å¹¶è¡Œ
    if use_concurrency:
        # ä»ç¯å¢ƒå˜é‡è·å–å¹¶å‘æ•°ï¼Œé»˜è®¤ä¸º 5
        max_workers = int(os.environ.get("MAX_IMG_WORKERS", "5"))
    else:
        max_workers = 1

    # ä½¿ç”¨ ThreadPoolExecutorï¼Œå³ä½¿ max_workers=1 ä¹Ÿå¯ä»¥ç»Ÿä¸€ä»£ç ç»“æ„
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        # æäº¤ä»»åŠ¡
        future_to_match = {
            executor.submit(
                analyze_image_with_llm,
                task[1],  # img_path
                llm_client,
                llm_model,
                5,  # max_retries
                2.0,  # base_delay (å¹¶å‘æ—¶ç¨å¾®å¢åŠ é€€é¿åŸºæ•°)
                logger,
            ): task
            for task in tasks
        }

        # è·å–ç»“æœ
        for completed_count, future in enumerate(
            concurrent.futures.as_completed(future_to_match), 1
        ):
            match, img_path, img_path_str = future_to_match[future]

            try:
                description = future.result()
                if description:
                    # è®°å½•æ›¿æ¢ä¿¡æ¯ï¼š(start_index, end_index, new_text)
                    new_ref = f"![{description}]({img_path_str})"
                    replacements.append((match.start(), match.end(), new_ref))
                    logger(
                        f"        âœ… [{completed_count}/{len(matches)}] {description[:30]}... ({img_path.name})"
                    )
                else:
                    logger(
                        f"        â­ï¸  [{completed_count}/{len(matches)}] æ— æè¿° ({img_path.name})"
                    )
            except Exception as e:
                logger(f"        âš ï¸  [{completed_count}/{len(matches)}] åˆ†æå¼‚å¸¸: {e}")

    # æŒ‰ä½ç½®ä»åå¾€å‰æ›¿æ¢ï¼Œé¿å…ç´¢å¼•åç§»
    replacements.sort(key=lambda x: x[0], reverse=True)

    result = markdown_text
    for start, end, new_text in replacements:
        result = result[:start] + new_text + result[end:]

    return result


@lru_cache(maxsize=1)
def find_libreoffice() -> str | None:
    """æŸ¥æ‰¾ LibreOffice å¯æ‰§è¡Œæ–‡ä»¶è·¯å¾„"""
    possible_paths = [
        # Windows
        r"C:\Program Files\LibreOffice\program\soffice.exe",
        r"C:\Program Files (x86)\LibreOffice\program\soffice.exe",
        # Linux
        "/usr/bin/soffice",
        "/usr/bin/libreoffice",
        # macOS
        "/Applications/LibreOffice.app/Contents/MacOS/soffice",
    ]

    for path in possible_paths:
        if os.path.exists(path):
            return path

    for cmd in ["soffice", "libreoffice"]:
        if shutil.which(cmd):
            return cmd

    return None


def check_ms_office_available() -> bool:
    """æ£€æŸ¥ Windows ä¸Šæ˜¯å¦å®‰è£…äº† MS Office PowerPoint"""
    if sys.platform != "win32":
        return False

    try:
        # é€šè¿‡æ³¨å†Œè¡¨æ£€æŸ¥ PowerPoint æ˜¯å¦å®‰è£…
        import winreg

        try:
            key = winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r"PowerPoint.Application")
            winreg.CloseKey(key)
            return True
        except OSError:  # WindowsError æ˜¯ OSError çš„åˆ«åï¼Œä½¿ç”¨ OSError æ›´é€šç”¨
            return False
    except ImportError:
        return False


def check_ms_word_available() -> bool:
    """æ£€æŸ¥ Windows ä¸Šæ˜¯å¦å®‰è£…äº† MS Office Word"""
    if sys.platform != "win32":
        return False

    try:
        import winreg

        try:
            key = winreg.OpenKey(winreg.HKEY_CLASSES_ROOT, r"Word.Application")
            winreg.CloseKey(key)
            return True
        except OSError:  # WindowsError æ˜¯ OSError çš„åˆ«åï¼Œä½¿ç”¨ OSError æ›´é€šç”¨
            return False
    except ImportError:
        return False


def convert_with_ms_office(input_file: Path, output_dir: Path) -> Path | None:
    """ä½¿ç”¨ MS Office PowerPoint è½¬æ¢ .ppt åˆ° .pptxï¼ˆä»… Windowsï¼‰"""
    if sys.platform != "win32":
        return None

    output_file = output_dir / (input_file.stem + ".pptx")

    # è½¬ä¹‰è·¯å¾„ä¸­çš„å•å¼•å·ï¼Œé˜²æ­¢ PowerShell è¯­æ³•é”™è¯¯
    input_path = str(input_file.resolve()).replace("'", "''")
    output_path = str(output_file.resolve()).replace("'", "''")

    # ä½¿ç”¨ PowerShell è°ƒç”¨ COM å¯¹è±¡ï¼Œé¿å…é¢å¤–ä¾èµ–
    ps_script = f"""
$ppt = New-Object -ComObject PowerPoint.Application
$ppt.Visible = [Microsoft.Office.Core.MsoTriState]::msoFalse
try {{
    $presentation = $ppt.Presentations.Open('{input_path}', $true, $false, $false)
    $presentation.SaveAs('{output_path}', 24)  # 24 = ppSaveAsOpenXMLPresentation
    $presentation.Close()
    Write-Host "SUCCESS"
}} catch {{
    Write-Host "FAILED: $_"
}} finally {{
    $ppt.Quit()
    [System.Runtime.Interopservices.Marshal]::ReleaseComObject($ppt) | Out-Null
}}
"""

    try:
        result = subprocess.run(
            ["powershell", "-NoProfile", "-Command", ps_script],
            capture_output=True,
            text=True,
            timeout=120,
        )

        if "SUCCESS" in result.stdout and output_file.exists():
            return output_file
        else:
            return None

    except Exception:
        return None


def convert_doc_with_ms_word(input_file: Path, output_dir: Path) -> Path | None:
    """ä½¿ç”¨ MS Office Word è½¬æ¢ .doc åˆ° .docxï¼ˆä»… Windowsï¼‰"""
    if sys.platform != "win32":
        return None

    output_file = output_dir / (input_file.stem + ".docx")

    # è½¬ä¹‰è·¯å¾„ä¸­çš„å•å¼•å·ï¼Œé˜²æ­¢ PowerShell è¯­æ³•é”™è¯¯
    input_path = str(input_file.resolve()).replace("'", "''")
    output_path = str(output_file.resolve()).replace("'", "''")

    # ä½¿ç”¨ PowerShell è°ƒç”¨ COM å¯¹è±¡
    ps_script = f"""
$word = New-Object -ComObject Word.Application
$word.Visible = $false
try {{
    $doc = $word.Documents.Open('{input_path}')
    $doc.SaveAs2('{output_path}', 16)  # 16 = wdFormatDocumentDefault (.docx)
    $doc.Close()
    Write-Host "SUCCESS"
}} catch {{
    Write-Host "FAILED: $_"
}} finally {{
    $word.Quit()
    [System.Runtime.Interopservices.Marshal]::ReleaseComObject($word) | Out-Null
}}
"""

    try:
        result = subprocess.run(
            ["powershell", "-NoProfile", "-Command", ps_script],
            capture_output=True,
            text=True,
            timeout=120,
        )

        if "SUCCESS" in result.stdout and output_file.exists():
            return output_file
        else:
            return None

    except Exception:
        return None


def convert_with_libreoffice(input_file: Path, output_dir: Path, new_ext: str) -> Path | None:
    """ä½¿ç”¨ LibreOffice è½¬æ¢æ—§æ ¼å¼"""
    libreoffice = find_libreoffice()
    if not libreoffice:
        return None

    cmd = [
        libreoffice,
        "--headless",
        "--convert-to",
        new_ext[1:],  # å»æ‰ç‚¹å·
        "--outdir",
        str(output_dir),
        str(input_file),
    ]

    try:
        subprocess.run(cmd, capture_output=True, text=True, timeout=120)
        new_file = output_dir / (input_file.stem + new_ext)
        if new_file.exists():
            return new_file
        return None
    except Exception:
        return None


def convert_old_format(input_file: Path, temp_dir: Path, logger=logger.info) -> Path | None:
    """è½¬æ¢æ—§æ ¼å¼æ–‡ä»¶ï¼ˆ.ppt/.doc ç­‰ï¼‰"""
    suffix = input_file.suffix.lower()
    new_ext = OLD_FORMATS.get(suffix)

    if not new_ext:
        return input_file

    temp_dir.mkdir(parents=True, exist_ok=True)

    # å¯¹äº .ppt æ–‡ä»¶ï¼Œä¼˜å…ˆä½¿ç”¨ MS Officeï¼ˆWindowsï¼‰
    if suffix == ".ppt":
        # 1. å°è¯• MS Officeï¼ˆWindows ä¼˜å…ˆï¼‰
        if check_ms_office_available():
            logger("  ğŸ”„ ä½¿ç”¨ MS Office è½¬æ¢ .ppt â†’ .pptx ...")
            result = convert_with_ms_office(input_file, temp_dir)
            if result:
                return result
            logger("      âš ï¸ MS Office è½¬æ¢å¤±è´¥ï¼Œå°è¯• LibreOffice...")

        # 2. å°è¯• LibreOffice
        libreoffice = find_libreoffice()
        if libreoffice:
            logger("  ğŸ”„ ä½¿ç”¨ LibreOffice è½¬æ¢ .ppt â†’ .pptx ...")
            result = convert_with_libreoffice(input_file, temp_dir, new_ext)
            if result:
                return result
            logger("      âš ï¸ LibreOffice è½¬æ¢å¤±è´¥")

        # 3. éƒ½å¤±è´¥ï¼Œæç¤ºç”¨æˆ·æ‰‹åŠ¨è½¬æ¢
        logger("  âš ï¸ æ— æ³•è‡ªåŠ¨è½¬æ¢ .ppt æ–‡ä»¶")
        logger("      ğŸ“Œ å»ºè®®ï¼šç”¨ PowerPoint æ‰“å¼€åå¦å­˜ä¸º .pptx æ ¼å¼")
        logger("      ï¼ˆæ‰‹åŠ¨è½¬æ¢åå¯ä¿ç•™å®Œæ•´çš„å›¾ç‰‡å’Œæ ¼å¼ï¼‰")
        return None

    # å¯¹äº .doc æ–‡ä»¶
    if suffix == ".doc":
        # 1. å°è¯• MS Wordï¼ˆWindows ä¼˜å…ˆï¼‰
        if check_ms_word_available():
            logger("  ğŸ”„ ä½¿ç”¨ MS Word è½¬æ¢ .doc â†’ .docx ...")
            result = convert_doc_with_ms_word(input_file, temp_dir)
            if result:
                return result
            logger("      âš ï¸ MS Word è½¬æ¢å¤±è´¥ï¼Œå°è¯• LibreOffice...")

        # 2. å°è¯• LibreOffice
        libreoffice = find_libreoffice()
        if libreoffice:
            logger("  ğŸ”„ ä½¿ç”¨ LibreOffice è½¬æ¢ .doc â†’ .docx ...")
            result = convert_with_libreoffice(input_file, temp_dir, new_ext)
            if result:
                return result
            logger("      âš ï¸ LibreOffice è½¬æ¢å¤±è´¥")

        # 3. éƒ½å¤±è´¥ï¼Œæç¤ºç”¨æˆ·æ‰‹åŠ¨è½¬æ¢
        logger("  âš ï¸ æ— æ³•è‡ªåŠ¨è½¬æ¢ .doc æ–‡ä»¶")
        logger("      ğŸ“Œ å»ºè®®ï¼šç”¨ Word æ‰“å¼€åå¦å­˜ä¸º .docx æ ¼å¼")
        logger("      ï¼ˆæ‰‹åŠ¨è½¬æ¢åå¯ä¿ç•™å®Œæ•´çš„å›¾ç‰‡å’Œæ ¼å¼ï¼‰")
        return None

    return None


def sanitize_filename(name: str) -> str:
    """å°†æ–‡ä»¶åä¸­çš„ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦æ›¿æ¢ä¸ºä¸‹åˆ’çº¿ï¼Œç¡®ä¿ Markdown å…¼å®¹"""
    # æ›¿æ¢ç©ºæ ¼å’Œå¸¸è§ç‰¹æ®Šå­—ç¬¦ä¸ºä¸‹åˆ’çº¿ï¼ˆä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™ï¼‰
    result = RE_SANITIZE_CHARS.sub("_", name)
    # åˆå¹¶è¿ç»­çš„ä¸‹åˆ’çº¿ï¼ˆä½¿ç”¨é¢„ç¼–è¯‘æ­£åˆ™ï¼‰
    result = RE_MULTI_UNDERSCORE.sub("_", result)
    # å»é™¤é¦–å°¾ä¸‹åˆ’çº¿
    result = result.strip("_")
    return result if result else "image"


def extract_base64_images(
    markdown_text: str, assets_dir: Path, file_stem: str, logger=logger.info
) -> str:
    """ä» Markdown ä¸­æå– base64 å›¾ç‰‡ï¼Œä¿å­˜åˆ° assets ç›®å½•ï¼Œæ›¿æ¢ä¸ºç›¸å¯¹è·¯å¾„

    å¯¹äº EMF/WMF ç­‰ Markdown ä¸æ”¯æŒçš„æ ¼å¼ï¼Œå°è¯•è½¬æ¢ä¸º PNGï¼Œå¤±è´¥åˆ™è·³è¿‡
    """
    # ä½¿ç”¨é¢„ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼

    # æ¸…ç†æ–‡ä»¶åå‰ç¼€
    safe_stem = sanitize_filename(file_stem)
    img_count = 0
    skip_count = 0

    # Markdown/æµè§ˆå™¨æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    SUPPORTED_IMG_FORMATS = {
        "jpeg",
        "jpg",
        "png",
        "gif",
        "webp",
        "bmp",
        "svg+xml",
        "svg",
    }
    # éœ€è¦è½¬æ¢çš„æ ¼å¼
    CONVERTIBLE_FORMATS = {"x-emf", "emf", "x-wmf", "wmf", "tiff", "tif"}

    def try_convert_to_png(img_data: bytes, original_format: str) -> bytes | None:
        """å°è¯•å°†ä¸æ”¯æŒçš„å›¾ç‰‡æ ¼å¼è½¬æ¢ä¸º PNG"""
        try:
            # io å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥
            from PIL import Image

            # å°è¯•ç”¨ Pillow æ‰“å¼€å¹¶è½¬æ¢
            img = Image.open(io.BytesIO(img_data))

            # è½¬æ¢ä¸º RGBï¼ˆå¤„ç† RGBAã€P ç­‰æ¨¡å¼ï¼‰
            if img.mode in ("RGBA", "LA", "P"):
                # ä¿æŒé€æ˜åº¦
                img = img.convert("RGBA")
            elif img.mode != "RGB":
                img = img.convert("RGB")

            # ä¿å­˜ä¸º PNG
            output = io.BytesIO()
            img.save(output, format="PNG")
            return output.getvalue()

        except Exception as e:
            # Pillow å¤±è´¥ï¼Œå¦‚æœæ˜¯ EMF/WMFï¼Œå°è¯•ä½¿ç”¨ LibreOffice è½¬æ¢
            # LibreOffice æ”¯æŒ headless è½¬æ¢: soffice --headless --convert-to png --outdir ... file.emf
            is_emf = original_format.lower() in ("emf", "wmf", "x-emf", "x-wmf")
            libreoffice = find_libreoffice()

            if is_emf and libreoffice:
                try:
                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆuuid å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼‰
                    temp_name = f"temp_{uuid.uuid4().hex[:8]}"
                    # å»æ‰ x- å‰ç¼€ï¼Œlibreoffice å¯èƒ½æ›´å–œæ¬¢æ ‡å‡†æ‰©å±•å
                    ext = original_format.replace("x-", "")
                    temp_emf = assets_dir / f"{temp_name}.{ext}"
                    temp_png = assets_dir / f"{temp_name}.png"

                    assets_dir.mkdir(parents=True, exist_ok=True)
                    temp_emf.write_bytes(img_data)

                    cmd = [
                        libreoffice,
                        "--headless",
                        "--convert-to",
                        "png",
                        "--outdir",
                        str(assets_dir),
                        str(temp_emf),
                    ]

                    # è½¬æ¢
                    subprocess.run(cmd, capture_output=True, timeout=30)

                    if temp_png.exists():
                        png_data = temp_png.read_bytes()
                        # æ¸…ç†
                        try:
                            temp_emf.unlink(missing_ok=True)
                            temp_png.unlink(missing_ok=True)
                        except Exception:
                            pass
                        return png_data

                    # æ¸…ç†å¤±è´¥çš„ä¸´æ—¶æ–‡ä»¶
                    with contextlib.suppress(Exception):
                        temp_emf.unlink(missing_ok=True)

                except Exception as e2:
                    logger(f"        âš ï¸ LibreOffice è½¬æ¢å¤±è´¥: {e2}")

            logger(f"        âš ï¸ æ ¼å¼è½¬æ¢å¤±è´¥ ({original_format}): {e}")
            return None

    def replace_image(match):
        nonlocal img_count, skip_count

        alt_text = match.group(1)
        img_format = match.group(2).lower()
        base64_data = match.group(3)

        try:
            img_data = base64.b64decode(base64_data)
        except Exception as e:
            logger(f"      âš ï¸ base64 è§£ç å¤±è´¥: {e}")
            skip_count += 1
            return ""  # ç§»é™¤æ— æ•ˆå›¾ç‰‡

        # æ£€æŸ¥æ˜¯å¦éœ€è¦è½¬æ¢
        if img_format in CONVERTIBLE_FORMATS:
            # logger(f"      ğŸ”„ è½¬æ¢ {img_format} æ ¼å¼...")
            converted_data = try_convert_to_png(img_data, img_format)
            if converted_data:
                img_data = converted_data
                img_format = "png"
            else:
                logger(f"      â­ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ ¼å¼: {img_format}")
                skip_count += 1
                return ""  # ç§»é™¤æ— æ³•è½¬æ¢çš„å›¾ç‰‡

        # æ£€æŸ¥æ˜¯å¦æ˜¯æ”¯æŒçš„æ ¼å¼
        if img_format not in SUPPORTED_IMG_FORMATS:
            logger(f"      â­ï¸  è·³è¿‡ä¸æ”¯æŒçš„æ ¼å¼: {img_format}")
            skip_count += 1
            return ""  # ç§»é™¤ä¸æ”¯æŒçš„æ ¼å¼

        img_count += 1

        ext_map = {
            "jpeg": ".jpg",
            "jpg": ".jpg",
            "png": ".png",
            "gif": ".gif",
            "webp": ".webp",
            "bmp": ".bmp",
            "svg+xml": ".svg",
            "svg": ".svg",
        }
        ext = ext_map.get(img_format, f".{img_format}")

        img_filename = f"{safe_stem}_{img_count:03d}{ext}"
        img_path = assets_dir / img_filename

        try:
            assets_dir.mkdir(parents=True, exist_ok=True)
            img_path.write_bytes(img_data)
            # logger(f"      ğŸ“· {img_filename}")
        except Exception as e:
            logger(f"      âš ï¸ å›¾ç‰‡ä¿å­˜å¤±è´¥: {e}")
            return match.group(0)

        return f"![{alt_text}](assets/{img_filename})"

    result = RE_BASE64_IMAGE.sub(replace_image, markdown_text)
    return result


def extract_pptx_text_fallback(input_file: Path) -> str | None:
    """å½“ MarkItDown å¤±è´¥æ—¶ï¼Œä½¿ç”¨ python-pptx ç›´æ¥æå–æ–‡æœ¬ï¼ˆä¸å«å›¾ç‰‡ï¼‰

    æ³¨æ„ï¼špython-pptx å·²éš markitdown[all] å®‰è£…ï¼Œæ— éœ€é¢å¤–å®‰è£…
    """
    try:
        from pptx import Presentation

        prs = Presentation(str(input_file))
        markdown_parts = []

        for slide_num, slide in enumerate(prs.slides, 1):
            markdown_parts.append(f"\n## å¹»ç¯ç‰‡ {slide_num}\n\n")

            for shape in slide.shapes:
                # æå–æ–‡æœ¬æ¡†å†…å®¹
                if shape.has_text_frame:
                    for paragraph in shape.text_frame.paragraphs:  # type: ignore
                        text = paragraph.text.strip()
                        if text:
                            # å°è¯•æ ¹æ®å­—ä½“å¤§å°åˆ¤æ–­å±‚çº§
                            try:
                                if paragraph.runs and paragraph.runs[0].font.size:
                                    font_size = paragraph.runs[0].font.size.pt
                                    if font_size and font_size >= 24:
                                        markdown_parts.append(f"### {text}\n\n")
                                    elif font_size and font_size >= 18:
                                        markdown_parts.append(f"**{text}**\n\n")
                                    else:
                                        markdown_parts.append(f"- {text}\n")
                                else:
                                    markdown_parts.append(f"- {text}\n")
                            except Exception:
                                markdown_parts.append(f"- {text}\n")

                # æå–è¡¨æ ¼
                if shape.has_table:
                    table = shape.table  # type: ignore
                    markdown_parts.append("\n")
                    for row_idx, row in enumerate(table.rows):
                        cells = [cell.text.strip().replace("\n", " ") for cell in row.cells]
                        markdown_parts.append("| " + " | ".join(cells) + " |\n")
                        if row_idx == 0:
                            markdown_parts.append("| " + " | ".join(["---"] * len(cells)) + " |\n")
                    markdown_parts.append("\n")

            markdown_parts.append("\n")

        return "".join(markdown_parts)

    except Exception as e:
        logger.error(f"      âš ï¸ å¤‡é€‰æå–å¤±è´¥: {e}")
        return None


def convert_to_markdown(
    input_file: Path,
    output_dir: Path,
    assets_dir: Path,
    md: MarkItDown,
    llm_client=None,
    llm_model: str | None = None,
    optimize: bool | None = False,
    analyze_attachments: bool | None = False,
    output_filename: str | None = None,
    logger=logger.info,
) -> bool:
    """å°†æ–‡ä»¶è½¬æ¢ä¸º Markdownï¼Œæå–å›¾ç‰‡ï¼Œå¯é€‰æ ¼å¼ä¼˜åŒ–å’Œé™„ä»¶å›¾ç‰‡åˆ†æ

    Args:
        md: MarkItDown å®ä¾‹ï¼ˆæ ¹æ®æ–‡ä»¶ç±»å‹å¯èƒ½å¸¦æˆ–ä¸å¸¦ LLM é…ç½®ï¼‰
        analyze_attachments: ä½¿ç”¨ LLM åˆ†ææ–‡æ¡£ä¸­æå–å‡ºçš„é™„ä»¶å›¾ç‰‡
        output_filename: æŒ‡å®šè¾“å‡ºæ–‡ä»¶åï¼ˆå¯é€‰ï¼Œç”¨äºé˜²é‡åï¼‰
        logger: æ—¥å¿—å¤„ç†å‡½æ•°
    """
    markdown_text = None

    # ç¬¬ä¸€æ¬¡å°è¯•ï¼šå¸¦å›¾ç‰‡æå–
    try:
        result = md.convert(str(input_file), keep_data_uris=True)
        markdown_text = result.text_content

        # æå– base64 å›¾ç‰‡
        markdown_text = extract_base64_images(
            markdown_text, assets_dir, input_file.stem, logger=logger
        )

        # å¤„ç† Excel è½¬æ¢ç»“æœä¸­çš„ NaN å€¼ï¼ˆç®€å•ç­–ç•¥ï¼šå°†è¡¨æ ¼ä¸­çš„ NaN æ›¿æ¢ä¸ºç©ºç™½ï¼‰
        if input_file.suffix.lower() in (".xls", ".xlsx") and markdown_text:
            markdown_text = re.sub(r"\|\s*NaN\s*\|", "||", markdown_text)

    except Exception as e:
        error_msg = str(e)

        # æ£€æŸ¥æ˜¯å¦æ˜¯å›¾ç‰‡è¯†åˆ«é”™è¯¯ï¼ˆå¸¸è§äºæ—§ç‰ˆ PPT çš„ WMF/EMF å›¾ç‰‡ï¼‰
        if "UnidentifiedImageError" in error_msg or "cannot identify image file" in error_msg:
            logger("  âš ï¸ åŒ…å«æ— æ³•è¯†åˆ«çš„å›¾ç‰‡æ ¼å¼ï¼Œä½¿ç”¨çº¯æ–‡æœ¬æå–...")

            # å¯¹äº PPTX æ–‡ä»¶ï¼Œä½¿ç”¨ python-pptx å¤‡é€‰æ–¹æ¡ˆ
            if input_file.suffix.lower() in (".pptx",):
                markdown_text = extract_pptx_text_fallback(input_file)
                if not markdown_text:
                    return False
            else:
                # å…¶ä»–æ ¼å¼å°è¯•ä¸å¸¦å›¾ç‰‡æå–
                try:
                    result = md.convert(str(input_file))
                    markdown_text = result.text_content
                except Exception as e2:
                    logger(f"  âŒ è½¬æ¢å¤±è´¥: {e2}")
                    return False
        else:
            logger(f"  âŒ è½¬æ¢å¤±è´¥: {e}")
            return False

    # æ£€æŸ¥æ–‡æœ¬é•¿åº¦ï¼Œå¦‚æœè¶…è¿‡é˜ˆå€¼åˆ™è·³è¿‡æ‰€æœ‰ LLM å¤„ç†ï¼ˆå›¾ç‰‡åˆ†æå’Œæ ¼å¼ä¼˜åŒ–ï¼‰
    if (optimize or analyze_attachments) and llm_client and llm_model and markdown_text:
        DEFAULT_CHUNK_SIZE = 10000
        env_chunk_size = os.environ.get("LLM_CHUNK_SIZE")
        try:
            CHUNK_SIZE = int(env_chunk_size) if env_chunk_size else DEFAULT_CHUNK_SIZE
        except ValueError:
            CHUNK_SIZE = DEFAULT_CHUNK_SIZE

        text_length = len(markdown_text)
        if text_length > CHUNK_SIZE:
            logger(
                f"      âš ï¸ æ–‡æœ¬è¿‡é•¿ ({text_length} > {CHUNK_SIZE})ï¼Œè·³è¿‡æ‰€æœ‰ LLM å¤„ç†ï¼ˆåˆ†æä¸ä¼˜åŒ–ï¼‰"
            )
            analyze_attachments = False
            optimize = False

    # åˆ†ææå–å‡ºçš„é™„ä»¶å›¾ç‰‡ï¼ˆåœ¨æ ¼å¼ä¼˜åŒ–ä¹‹å‰ï¼‰
    if analyze_attachments and llm_client and llm_model and markdown_text:
        # ä¿®æ­£ï¼šç”¨æˆ·è¦æ±‚å®½æ¾çš„ä¼˜åŒ–ï¼Œæ‰€ä»¥è¿™é‡Œå¯ç”¨å¹¶å‘ã€‚
        # analyze_images_in_markdown ä¼šè¯»å– MAX_IMG_WORKERS (é»˜è®¤5)ã€‚
        markdown_text = analyze_images_in_markdown(
            markdown_text,
            assets_dir,
            llm_client,
            llm_model,
            use_concurrency=True,
            logger=logger,
        )

    # æ ¼å¼ä¼˜åŒ–ï¼ˆå¦‚æœå¯ç”¨ä¸”é…ç½®äº† LLMï¼‰
    if optimize and llm_client and llm_model and markdown_text:
        logger("      ğŸ”„ æ ¼å¼ä¼˜åŒ–ä¸­...")
        markdown_text = optimize_markdown_format(
            markdown_text,
            llm_client,
            llm_model,
            file_title=input_file.stem,
            logger=logger,
        )

    # å†™å…¥ Markdown æ–‡ä»¶
    if markdown_text is not None:
        if output_filename:
            output_file = output_dir / output_filename
        else:
            output_file = output_dir / (input_file.stem + ".md")

        if not markdown_text.strip():
            logger("      âš ï¸ è­¦å‘Šï¼šè½¬æ¢ç»“æœä¸ºç©º")
        output_file.write_text(markdown_text, encoding="utf-8")
        return True

    return False


def _process_single_file(
    file: Path,
    folder: Path,
    output_root: Path,
    temp_dir: Path,
    llm_client,
    llm_model: str | None,
    optimize: bool,
    analyze_attachments: bool,
) -> tuple[int, int, int]:
    """å¤„ç†å•ä¸ªæ–‡ä»¶çš„è¾…åŠ©å‡½æ•°ï¼ˆç”¨äºå¹¶è¡Œå¤„ç†ï¼‰"""
    global processed_count

    # è®¡ç®—ç›¸å¯¹è·¯å¾„
    rel_path = file.relative_to(folder)
    rel_dir = rel_path.parent

    # ç«‹å³è®°å½•å¼€å§‹å¤„ç†ï¼Œé¿å…ç”¨æˆ·è§‰å¾—å¡ä½
    logger.info(f"ğŸ”„ æ­£åœ¨å¤„ç†: {file.name}")

    # åˆ›å»ºå¯¹åº”çš„è¾“å‡ºç›®å½•ç»“æ„
    current_output_dir = output_root / rel_dir
    assets_dir = current_output_dir / "assets"
    current_output_dir.mkdir(parents=True, exist_ok=True)

    working_file = file

    # æ£€æŸ¥æ˜¯å¦æ˜¯éœ€è¦è½¬æ¢çš„æ—§æ ¼å¼
    if file.suffix.lower() in OLD_FORMATS:
        # ä½¿ç”¨å…¨å±€é”ä¿æŠ¤ Office è½¬æ¢ï¼Œé˜²æ­¢å¹¶å‘å†²çª
        with office_lock:
            working_file = convert_old_format(file, temp_dir, logger=logger.info)

        if working_file is None:
            with counter_lock:
                processed_count += 1
                curr_p = processed_count
            logger.warning(f"[{curr_p}/{total_count}] â­ï¸  {file.name} è·³è¿‡ (è½¬æ¢å¤±è´¥)")
            return 0, 0, 1  # success, fail, skip

    # åœ¨çº¿ç¨‹å†…éƒ¨åˆ›å»º MarkItDown å®ä¾‹ï¼Œç¡®ä¿çº¿ç¨‹å®‰å…¨
    llm_prompt = os.environ.get("LLM_PROMPT") or LLM_CONTENT_PROMPT

    file_ext = working_file.suffix.lower()
    if file_ext in IMAGE_FORMATS and llm_client:
        # å›¾ç‰‡æ–‡ä»¶ä¸”æœ‰ LLMï¼Œä½¿ç”¨å¸¦ LLM çš„å®ä¾‹
        md = MarkItDown(llm_client=llm_client, llm_model=llm_model, llm_prompt=llm_prompt)
    else:
        # å…¶ä»–æƒ…å†µä½¿ç”¨æ™®é€šå®ä¾‹
        md = MarkItDown()

    # è®¡ç®—è¾“å‡ºè·¯å¾„æ˜¾ç¤º
    base_name = file.stem
    output_filename = f"{base_name}.md"
    output_file = current_output_dir / output_filename

    # é˜²é‡åé€»è¾‘
    counter = 1
    while output_file.exists():
        output_filename = f"{base_name}_{counter}.md"
        output_file = current_output_dir / output_filename
        counter += 1

    output_rel = rel_dir / output_filename if rel_dir != Path(".") else Path(output_filename)

    success = convert_to_markdown(
        working_file,
        current_output_dir,
        assets_dir,
        md,
        llm_client,
        llm_model,
        optimize,
        analyze_attachments,
        output_filename=output_filename,
        logger=logger.info,
    )

    # å¤„ç†å®Œæˆåçš„è®°å½•
    with counter_lock:
        processed_count += 1
        curr_p = processed_count

    prefix = f"[{curr_p}/{total_count}]"
    if success:
        logger.info(f"{prefix} âœ… {file.name} -> {output_rel}")
        return 1, 0, 0
    else:
        logger.error(f"{prefix} âŒ {file.name} å¤±è´¥")
        return 0, 1, 0


def process_folder(
    folder_path: str,
    optimize: bool = False,
    analyze_attachments: bool = False,
    analyze_image_files: bool = False,
    output_dir: str | None = None,
):
    """å¤„ç†æŒ‡å®šæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰æ–‡ä»¶ï¼ˆåŒ…æ‹¬å­æ–‡ä»¶å¤¹ï¼‰

    Args:
        optimize: ä½¿ç”¨ LLM ä¼˜åŒ– Markdown æ ¼å¼
        analyze_attachments: ä½¿ç”¨ LLM åˆ†ææ–‡æ¡£ä¸­æå–å‡ºçš„é™„ä»¶å›¾ç‰‡
        analyze_image_files: ä½¿ç”¨ LLM åˆ†æå›¾ç‰‡æ–‡ä»¶
        output_dir: æŒ‡å®šè¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼‰
    """
    global total_count
    folder = Path(folder_path).resolve()

    if not folder.exists():
        logger.error(f"âŒ æ–‡ä»¶å¤¹ä¸å­˜åœ¨: {folder_path}")
        return

    if not folder.is_dir():
        logger.error(f"âŒ è·¯å¾„ä¸æ˜¯æ–‡ä»¶å¤¹: {folder_path}")
        return

    # ç¡®å®šè¾“å‡ºæ ¹ç›®å½•
    env_output = os.environ.get("OUTPUT_DIR")

    if output_dir:
        output_root = Path(output_dir).resolve()
    elif env_output:
        output_root = Path(env_output).resolve()
    else:
        output_root = folder.parent / "output"

    temp_dir = output_root / "_temp"

    output_root.mkdir(parents=True, exist_ok=True)

    # é€’å½’æŸ¥æ‰¾æ”¯æŒçš„æ–‡ä»¶
    all_files = []
    for f in folder.rglob("*"):
        if f.is_file() and f.suffix.lower() in SUPPORTED_FORMATS:
            try:
                f.relative_to(output_root)
                continue  # æ–‡ä»¶åœ¨ output ç›®å½•ä¸­ï¼Œè·³è¿‡
            except ValueError:
                pass
            all_files.append(f)

    if not all_files:
        logger.warning(f"âš ï¸ åœ¨ {folder} ä¸­æ²¡æœ‰æ‰¾åˆ°å¯è½¬æ¢çš„æ–‡ä»¶")
        logger.warning(f"   æ”¯æŒæ ¼å¼: {', '.join(sorted(SUPPORTED_FORMATS))}")
        return

    total_count = len(all_files)
    subdirs = {f.parent for f in all_files if f.parent != folder}
    image_files = [f for f in all_files if f.suffix.lower() in IMAGE_FORMATS]

    logger.info(f"ğŸ“‚ æ‰¾åˆ° {total_count} ä¸ªæ–‡ä»¶")
    if subdirs:
        logger.info(f"   åŒ…å« {len(subdirs)} ä¸ªå­æ–‡ä»¶å¤¹")
    logger.info(f"ğŸ“ è¾“å‡º: {output_root}")

    # åˆå§‹åŒ– LLMï¼ˆå¦‚æœé…ç½®äº†ä¸”éœ€è¦ï¼‰
    llm_client = None
    llm_model = None
    should_init_llm = optimize or analyze_attachments or analyze_image_files

    if should_init_llm:
        llm_client, llm_model = create_llm_client()

    # æ˜¾ç¤ºå¯ç”¨çš„åŠŸèƒ½
    if optimize:
        if llm_client:
            logger.info("âœ¨ å·²å¯ç”¨æ ¼å¼ä¼˜åŒ–")
        else:
            logger.warning("âš ï¸ æ ¼å¼ä¼˜åŒ–éœ€è¦é…ç½® LLMï¼Œå·²è·³è¿‡")
            optimize = False

    if analyze_attachments:
        if llm_client:
            logger.info("ğŸ” å·²å¯ç”¨é™„ä»¶å›¾ç‰‡åˆ†æ")
        else:
            logger.warning("âš ï¸ é™„ä»¶å›¾ç‰‡åˆ†æéœ€è¦é…ç½® LLMï¼Œå·²è·³è¿‡")
            analyze_attachments = False

    if analyze_image_files:
        if llm_client:
            logger.info("ğŸ–¼ï¸ å·²å¯ç”¨å›¾ç‰‡æ–‡ä»¶åˆ†æ")
        else:
            logger.warning("âš ï¸ å›¾ç‰‡æ–‡ä»¶åˆ†æéœ€è¦é…ç½® LLMï¼Œå·²è·³è¿‡")
            analyze_image_files = False

    # æç¤ºæœªå¯ç”¨çš„åŠŸèƒ½
    if image_files and not analyze_image_files:
        logger.info(
            f"ğŸ’¡ æ£€æµ‹åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶ï¼ˆä½¿ç”¨ --analyze-image-files å¯ç”¨ LLM æè¿°ï¼‰"
        )

    logger.info("-" * 50)

    success, fail, skip = 0, 0, 0
    max_workers = int(os.environ.get("MAX_WORKERS", "10"))
    logger.info(f"ğŸš€ å¯åŠ¨ {max_workers} ä¸ªçº¿ç¨‹è¿›è¡Œå¹¶è¡Œå¤„ç†...")

    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        future_to_file = {
            executor.submit(
                _process_single_file,
                file,
                folder,
                output_root,
                temp_dir,
                llm_client,
                llm_model,
                optimize,
                analyze_attachments,
            ): file
            for file in sorted(all_files)
        }

        for future in concurrent.futures.as_completed(future_to_file):
            try:
                s, f, sk = future.result()
                success += s
                fail += f
                skip += sk
            except Exception as e:
                file_path = future_to_file[future]
                logger.error(f"âŒ å¤„ç†æ–‡ä»¶å¼‚å¸¸ {file_path.name}: {e}")
                fail += 1

    # æ¸…ç†
    if temp_dir.exists():
        shutil.rmtree(temp_dir)

    # æ¸…ç†ç©ºçš„ assets ç›®å½•ï¼ˆé€’å½’ï¼‰
    for assets in output_root.rglob("assets"):
        if assets.is_dir() and not any(assets.iterdir()):
            assets.rmdir()

    # ç»Ÿè®¡
    logger.info("=" * 50)
    logger.info(f"âœ¨ å®Œæˆ! æˆåŠŸ: {success}")
    if fail:
        logger.info(f"   å¤±è´¥: {fail}")
    if skip:
        logger.info(f"   è·³è¿‡: {skip} (éœ€è¦ LibreOffice æˆ–è½¬æ¢å¤±è´¥)")
    logger.info(f"ğŸ“ è¾“å‡ºä½ç½®: {output_root}")


def process_file(
    file_path: str,
    output_dir: str | None = None,
    optimize: bool | None = False,
    analyze_attachments: bool | None = False,
    analyze_image_files: bool | None = None,
):
    """å¤„ç†å•ä¸ªæ–‡ä»¶"""
    global total_count
    input_file = Path(file_path).resolve()
    total_count = 1

    if not input_file.exists():
        logger.error(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
        return

    if not input_file.is_file():
        logger.error(f"âŒ è·¯å¾„ä¸æ˜¯æ–‡ä»¶: {file_path}")
        return

    if input_file.suffix.lower() not in SUPPORTED_FORMATS:
        logger.error(f"âŒ ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {input_file.suffix}")
        return

    # è‡ªåŠ¨åˆ¤æ–­
    is_image_file = input_file.suffix.lower() in IMAGE_FORMATS
    if analyze_image_files is None:
        analyze_image_files = is_image_file

    # ç¡®å®šè¾“å‡ºç›®å½•
    env_output = os.environ.get("OUTPUT_DIR")
    if output_dir:
        out_dir = Path(output_dir).resolve()
    elif env_output:
        out_dir = Path(env_output).resolve()
    else:
        out_dir = input_file.parent

    assets_dir = out_dir / "assets"
    temp_dir = out_dir / "_temp"

    out_dir.mkdir(parents=True, exist_ok=True)

    logger.info(f"ğŸ“„ å¤„ç†æ–‡ä»¶: {input_file.name}")
    logger.info(f"ğŸ“ è¾“å‡ºç›®å½•: {out_dir}")

    # åˆå§‹åŒ– LLM
    llm_client = None
    llm_model = None
    should_init_llm = optimize or analyze_attachments or analyze_image_files

    if should_init_llm:
        llm_client, llm_model = create_llm_client()

    # æ˜¾ç¤ºå¯ç”¨çš„åŠŸèƒ½
    if optimize:
        if llm_client:
            logger.info("âœ¨ å·²å¯ç”¨æ ¼å¼ä¼˜åŒ–")
        else:
            logger.warning("âš ï¸ æ ¼å¼ä¼˜åŒ–éœ€è¦é…ç½® LLMï¼Œå·²è·³è¿‡")
            optimize = False

    if analyze_attachments:
        if llm_client:
            logger.info("ğŸ” å·²å¯ç”¨é™„ä»¶å›¾ç‰‡åˆ†æ")
        else:
            logger.warning("âš ï¸ é™„ä»¶å›¾ç‰‡åˆ†æéœ€è¦é…ç½® LLMï¼Œå·²è·³è¿‡")
            analyze_attachments = False

    if analyze_image_files:
        if llm_client:
            logger.info("ğŸ–¼ï¸ å›¾ç‰‡æ–‡ä»¶å°†ä½¿ç”¨ LLM ç”Ÿæˆæè¿°")
        else:
            logger.warning("âš ï¸ å›¾ç‰‡æ–‡ä»¶åˆ†æéœ€è¦é…ç½® LLMï¼Œå·²è·³è¿‡")
            analyze_image_files = False

    logger.info("-" * 50)

    # è·å–è‡ªå®šä¹‰æç¤ºè¯
    llm_prompt = os.environ.get("LLM_PROMPT") or LLM_CONTENT_PROMPT

    # æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹© MarkItDown å®ä¾‹
    file_ext = input_file.suffix.lower()
    use_llm_for_markitdown = analyze_image_files and llm_client and file_ext in IMAGE_FORMATS

    if use_llm_for_markitdown:
        md = MarkItDown(llm_client=llm_client, llm_model=llm_model, llm_prompt=llm_prompt)
    else:
        md = MarkItDown()

    # å¤„ç†æ—§æ ¼å¼
    working_file = input_file
    if input_file.suffix.lower() in OLD_FORMATS:
        working_file = convert_old_format(input_file, temp_dir, logger=logger.info)
        if working_file is None:
            return

    # è½¬æ¢
    success = convert_to_markdown(
        working_file,
        out_dir,
        assets_dir,
        md,
        llm_client,
        llm_model,
        optimize,
        analyze_attachments,
        logger=logger.info,
    )

    if success:
        logger.info(f"âœ… è½¬æ¢æˆåŠŸ: {out_dir / (input_file.stem + '.md')}")
    else:
        logger.error("âŒ è½¬æ¢å¤±è´¥")

    # æ¸…ç†
    if temp_dir.exists():
        shutil.rmtree(temp_dir)
    if assets_dir.exists() and not any(assets_dir.iterdir()):
        assets_dir.rmdir()

    # æ¸…ç†
    if temp_dir.exists():
        shutil.rmtree(temp_dir)
    if assets_dir.exists() and not any(assets_dir.iterdir()):
        assets_dir.rmdir()


def main():
    # è§£å†³ Windows ä¸‹æ§åˆ¶å°ç¼–ç é—®é¢˜ï¼ˆio å·²åœ¨æ–‡ä»¶é¡¶éƒ¨å¯¼å…¥ï¼‰
    if sys.stdout.encoding != "utf-8":
        with contextlib.suppress(Exception):
            sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8")

    print("""
+===================================================+
|      Markdown æ‰¹é‡è½¬æ¢å·¥å…·                        |
|      æ–‡æ¡£ â†’ Markdownï¼ˆå«å›¾ç‰‡æå–ï¼‰                |
+===================================================+
    """)

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = sys.argv[1:]
    optimize = False
    analyze_attachments = False
    analyze_image_files = False
    analyze_image_files_explicit = False  # æ˜¯å¦æ˜¾å¼æŒ‡å®šäº†å‚æ•°
    target_path = None
    output_dir = None

    # æ£€æŸ¥ --optimize æˆ– -o å‚æ•°
    if "--optimize" in args:
        optimize = True
        args.remove("--optimize")
    if "-o" in args:
        optimize = True
        args.remove("-o")

    # æ£€æŸ¥ --analyze-attachments å‚æ•°
    if "--analyze-attachments" in args:
        analyze_attachments = True
        args.remove("--analyze-attachments")

    # æ£€æŸ¥ --analyze-image-files å‚æ•°
    if "--analyze-image-files" in args:
        analyze_image_files = True
        analyze_image_files_explicit = True
        args.remove("--analyze-image-files")

    # æ£€æŸ¥ --output æˆ– -out å‚æ•°
    if "--output" in args:
        idx = args.index("--output")
        if idx + 1 < len(args):
            output_dir = args[idx + 1]
            args.pop(idx + 1)
            args.pop(idx)
    if "-out" in args:
        idx = args.index("-out")
        if idx + 1 < len(args):
            output_dir = args[idx + 1]
            args.pop(idx + 1)
            args.pop(idx)

    # æ£€æŸ¥ --help æˆ– -h å‚æ•°
    if "--help" in args or "-h" in args:
        print('ç”¨æ³•: uv run convert_to_markdown.py [é€‰é¡¹] "æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„"')
        print()
        print("é€‰é¡¹:")
        print("  -o, --optimize            ä½¿ç”¨ LLM ä¼˜åŒ– Markdown æ ¼å¼")
        print("  --analyze-attachments     ä½¿ç”¨ LLM åˆ†ææ–‡æ¡£ä¸­æå–çš„é™„ä»¶å›¾ç‰‡")
        print("  --analyze-image-files     ä½¿ç”¨ LLM åˆ†æç‹¬ç«‹çš„å›¾ç‰‡æ–‡ä»¶")
        print("  -out, --output <dir>      æŒ‡å®šè¾“å‡ºç›®å½•")
        print("  -h, --help                æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯")
        print()
        print("è¯´æ˜:")
        print("  é»˜è®¤ä¸ä½¿ç”¨ LLM å¤„ç†å›¾ç‰‡")
        print("  ç›´æ¥æŒ‡å®šå›¾ç‰‡æ–‡ä»¶æ—¶ï¼Œ--analyze-image-files é»˜è®¤å¯ç”¨")
        print("  é•¿æ–‡æœ¬ï¼ˆè¶…è¿‡é˜ˆå€¼ï¼‰è·³è¿‡æ‰€æœ‰ LLM å¤„ç†ï¼ˆåˆ†æä¸ä¼˜åŒ–ï¼‰ï¼Œç›´æ¥è¿”å›åŸå§‹å†…å®¹")
        print("  æ‰€æœ‰é€‰é¡¹å¯ç‹¬ç«‹ä½¿ç”¨ï¼Œä¹Ÿå¯ç»„åˆä½¿ç”¨")
        print()
        print("ç¯å¢ƒå˜é‡ï¼ˆç”¨äº LLM åŠŸèƒ½ï¼‰:")
        print("  OPENAI_API_KEY      OpenAI API å¯†é’¥")
        print("  OPENAI_BASE_URL     è‡ªå®šä¹‰æ¥å£åœ°å€ï¼ˆå¦‚ OpenRouterï¼‰")
        print("  OPENAI_MODEL        æ¨¡å‹åç§°")
        print("  GOOGLE_API_KEY      Google Gemini API å¯†é’¥")
        print("  OLLAMA_MODEL        æœ¬åœ° Ollama æ¨¡å‹åç§°")
        print("  LLM_PROMPT          è‡ªå®šä¹‰å›¾ç‰‡æè¿°æç¤ºè¯")
        print("  LLM_CHUNK_SIZE      è¶…é•¿æ–‡æœ¬é˜ˆå€¼ï¼ˆé»˜è®¤ 10000 å­—ç¬¦ï¼‰")
        print("  MAX_WORKERS         æ–‡ä»¶å¹¶è¡Œå¤„ç†çº¿ç¨‹æ•°ï¼ˆé»˜è®¤ 10ï¼‰")
        print("  MAX_IMG_WORKERS     å•æ–‡ä»¶å†…å›¾ç‰‡å¹¶è¡Œåˆ†æçº¿ç¨‹æ•°ï¼ˆé»˜è®¤ 5ï¼‰")
        print("  OUTPUT_DIR          é»˜è®¤è¾“å‡ºç›®å½•")
        print()
        print("ç¤ºä¾‹:")
        print("  # è½¬æ¢æ–‡ä»¶å¤¹")
        print('  uv run convert_to_markdown.py "./documents"')
        print()
        print("  # æŒ‡å®šè¾“å‡ºç›®å½•")
        print('  uv run convert_to_markdown.py -out "./output" "./documents"')
        print()
        print("  # å¯ç”¨æ ¼å¼ä¼˜åŒ–")
        print('  uv run convert_to_markdown.py -o "./documents"')
        return

    # è·å–è·¯å¾„
    if args:
        target_path = args[0]
    else:
        print("è¯·è¾“å…¥è¦è½¬æ¢çš„æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„ï¼ˆå¯æ‹–å…¥ï¼‰:")
        target_path = input("> ").strip().strip('"').strip("'")

        # äº¤äº’æ¨¡å¼ä¸‹è¯¢é—®é€‰é¡¹
        if target_path:
            print("\næ˜¯å¦å¯ç”¨ LLM æ ¼å¼ä¼˜åŒ–ï¼Ÿ(y/N):")
            optimize_input = input("> ").strip().lower()
            optimize = optimize_input in ("y", "yes", "æ˜¯")

            print("\næ˜¯å¦å¯ç”¨é™„ä»¶å›¾ç‰‡åˆ†æï¼Ÿ(y/N):")
            attach_input = input("> ").strip().lower()
            analyze_attachments = attach_input in ("y", "yes", "æ˜¯")

            print("\næ˜¯å¦å¯ç”¨å›¾ç‰‡æ–‡ä»¶/PPTX å›¾ç‰‡åˆ†æï¼Ÿ(y/N):")
            img_input = input("> ").strip().lower()
            analyze_image_files = img_input in ("y", "yes", "æ˜¯")
            analyze_image_files_explicit = True

    if not target_path:
        print("\nâŒ æœªæä¾›è·¯å¾„")
        print('\nç”¨æ³•: uv run convert_to_markdown.py [é€‰é¡¹] "æ–‡ä»¶æˆ–æ–‡ä»¶å¤¹è·¯å¾„"')
        return

    # åˆ¤æ–­æ˜¯æ–‡ä»¶è¿˜æ˜¯æ–‡ä»¶å¤¹
    target = Path(target_path)
    if target.is_file():
        # å¯¹äºå•ä¸ªæ–‡ä»¶ï¼Œå¦‚æœæœªæ˜¾å¼æŒ‡å®š analyze_image_filesï¼Œåˆ™ä¼  Noneï¼ˆè‡ªåŠ¨åˆ¤æ–­ï¼‰
        img_files_arg = analyze_image_files if analyze_image_files_explicit else None
        process_file(
            target_path,
            output_dir=output_dir,
            optimize=optimize,
            analyze_attachments=analyze_attachments,
            analyze_image_files=img_files_arg,
        )
    elif target.is_dir():
        process_folder(
            target_path,
            output_dir=output_dir,
            optimize=optimize,
            analyze_attachments=analyze_attachments,
            analyze_image_files=analyze_image_files,
        )
    else:
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {target_path}")


if __name__ == "__main__":
    main()
