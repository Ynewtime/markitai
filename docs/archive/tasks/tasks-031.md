# markitai é—®é¢˜ä¿®å¤ä»»åŠ¡

> åŸºäº `logs/markitai_20260126_235833_480871.log` æ·±åº¦åˆ†æ
> æ›´æ–°æ—¶é—´: 2026-01-27 (æ·±åº¦åˆ†æ v2)

---

## ä»»åŠ¡æ€»è§ˆ

| # | é—®é¢˜ | ä¸¥é‡æ€§ | çŠ¶æ€ |
|---|------|--------|------|
| 1 | Browser æ‰“å¼€å¯è§ Terminal çª—å£ | Medium | **å·²ä¿®å¤** âœ… |
| 2 | **Prompt æ³„æ¼åˆ° LLM è¾“å‡º** | **Critical** | **å·²ä¿®å¤** âœ… |
| 3 | x.com è¶…æ—¶åŠé”™è¯¯æ¶ˆæ¯ä¸å‡†ç¡® | High | **å·²ä¿®å¤** âœ… |
| 4 | max_tokens è¶…å‡º deepseek é™åˆ¶ | High | **å·²ä¿®å¤** âœ… |
| 5 | å›¾ç‰‡ä¸‹è½½å¤±è´¥ (å¤–éƒ¨èµ„æº) | Low | ä¸ä¿®å¤ |

### Issue #2 å­ä»»åŠ¡è¿›åº¦

| å­ä»»åŠ¡ | Prompt æ–‡ä»¶ | ä½¿ç”¨æ–¹æ³• | çŠ¶æ€ |
|--------|-------------|----------|------|
| 2.1 | `document_process` | `_process_document_combined` | **å·²ä¿®å¤** âœ… |
| 2.2 | `cleaner` | `clean_markdown` | **å·²ä¿®å¤** âœ… |
| 2.3 | `frontmatter` | `generate_frontmatter` | **å·²ä¿®å¤** âœ… |

**ä¿®å¤è¯¦æƒ…**:
- æ¯ä¸ª prompt æ‹†åˆ†ä¸º `*_system.md` (è§’è‰²å®šä¹‰+è§„åˆ™) å’Œ `*_user.md` (ç”¨æˆ·å†…å®¹)
- LLM è°ƒç”¨ä½¿ç”¨ `[{"role": "system", ...}, {"role": "user", ...}]` æ¶ˆæ¯ç»“æ„
- æ–°å¢ `_validate_no_prompt_leakage` å‡½æ•°æ£€æµ‹å¹¶å¤„ç† prompt æ³„æ¼

---

## Issue #1: Browser æ‰“å¼€å¯è§ Terminal çª—å£

### é—®é¢˜æè¿°

Windows ä¸Šè¿è¡Œ agent-browser æ—¶ä¼šæ‰“å¼€å•ç‹¬çš„ Terminal çª—å£ï¼Œå½±å“ç”¨æˆ·ä½“éªŒã€‚

### æ ¹å› 

`fetch.py:730` çš„ `asyncio.create_subprocess_exec` åœ¨ Windows ä¸Šé»˜è®¤æ˜¾ç¤ºæ§åˆ¶å°çª—å£ã€‚

### ä¿®å¤æ–¹æ¡ˆ

```python
# fetch.py:_run_agent_browser_command
import subprocess

kwargs: dict = {
    "stdout": asyncio.subprocess.PIPE,
    "stderr": asyncio.subprocess.PIPE,
}
if sys.platform == "win32":
    kwargs["creationflags"] = subprocess.CREATE_NO_WINDOW

proc = await asyncio.create_subprocess_exec(*effective_args, **kwargs)
```

---

## Issue #2: Prompt æ³„æ¼åˆ° LLM è¾“å‡º (Critical)

### é—®é¢˜æè¿°

`concise.llm.md` çš„ `cleaned_markdown` å­—æ®µåŒ…å«å®Œæ•´çš„ prompt æ–‡æœ¬ï¼Œè€Œéå¤„ç†åçš„å†…å®¹ã€‚

### æ·±åº¦æ ¹å› åˆ†æ

**æ ¸å¿ƒé—®é¢˜ï¼šPrompt ä¸å†…å®¹æ··åˆåœ¨åŒä¸€ä¸ª user message ä¸­**

```python
# llm.py:4040-4042 (å½“å‰å®ç°)
messages = cast(
    list[ChatCompletionMessageParam],
    [{"role": "user", "content": prompt}],  # âŒ Prompt ä½œä¸º user å†…å®¹
)
```

**é—®é¢˜é“¾**ï¼š
1. `document_process.md` prompt åŒ…å«è¯¦ç»†çš„å¤„ç†è§„åˆ™ï¼ˆã€æ ¸å¿ƒåŸåˆ™ã€‘ã€æ¸…ç†è§„èŒƒã€‘ç­‰ï¼‰
2. Prompt å’Œæ–‡æ¡£å†…å®¹ä½œä¸ºå•ä¸ª user message ä¼ ç»™ LLM
3. LLM å¤„ç†æ—¶éš¾ä»¥åŒºåˆ†"æŒ‡ä»¤"å’Œ"å†…å®¹"
4. åœ¨ç”Ÿæˆ `cleaned_markdown` æ—¶ï¼ŒLLM å¯èƒ½å¤åˆ¶æ•´ä¸ªè¾“å…¥ï¼ˆåŒ…æ‹¬ promptï¼‰
5. Instructor åªéªŒè¯ JSON ç»“æ„ï¼Œä¸éªŒè¯å†…å®¹åˆç†æ€§

**ä¸ºä»€ä¹ˆæŸäº›æ¨¡å‹ä¼šæ³„æ¼ prompt**ï¼š
- deepseek-v3.2 åœ¨å¤„ç†é•¿æ–‡æœ¬æ—¶å¯èƒ½ä¼š"å¼•ç”¨"è¾“å…¥
- æ²¡æœ‰æ˜ç¡®çš„ system role æ¥éš”ç¦»æŒ‡ä»¤
- Pydantic model çš„ Field description æœªè¢«å……åˆ†åˆ©ç”¨

### ä¿®å¤æ–¹æ¡ˆï¼šæ‹†åˆ† System Prompt å’Œ User Prompt

**Step 1**: åˆ›å»º system prompt æ–‡ä»¶

**æ–‡ä»¶**: `packages/markitai/src/markitai/prompts/document_process_system.md`

```markdown
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ Markdown æ–‡æ¡£å¤„ç†åŠ©æ‰‹ã€‚

## ä½ çš„ä»»åŠ¡
1. **æ ¼å¼ä¼˜åŒ–**ï¼šæ¸…ç† Markdown æ ¼å¼ï¼Œä¿æŒåŸæ–‡è¯­è¨€ä¸å˜
2. **å…ƒæ•°æ®ç”Ÿæˆ**ï¼šæå–æ ‡é¢˜ã€æ‘˜è¦ã€æ ‡ç­¾

## å¤„ç†è§„åˆ™
- ç¦æ­¢ç¿»è¯‘ï¼šä¿ç•™åŸæ–‡è¯­è¨€
- ç¦æ­¢æ”¹å†™ï¼šåªåšæ ¼å¼è°ƒæ•´
- ä¿ç•™ä»£ç å—ã€è¡¨æ ¼ã€é“¾æ¥ã€å›¾ç‰‡è¯­æ³•
- ä¿ç•™æ‰€æœ‰ `__MARKITAI_*__` å ä½ç¬¦

## è¾“å‡ºæ ¼å¼
è¿”å› JSONï¼ŒåŒ…å«ï¼š
- cleaned_markdown: ä¼˜åŒ–åçš„ Markdownï¼ˆåªåŒ…å«æ–‡æ¡£å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å¤„ç†æŒ‡ä»¤ï¼‰
- frontmatter: { title, description, tags }

é‡è¦ï¼šcleaned_markdown å¿…é¡»åªåŒ…å«ä¼˜åŒ–åçš„æ–‡æ¡£å†…å®¹æœ¬èº«ï¼Œç»å¯¹ä¸è¦åŒ…å«ä»»ä½•ä»»åŠ¡è¯´æ˜æˆ– prompt æ–‡æœ¬ã€‚
```

**Step 2**: åˆ›å»º user prompt æ–‡ä»¶

**æ–‡ä»¶**: `packages/markitai/src/markitai/prompts/document_process_user.md`

```markdown
è¯·å¤„ç†ä»¥ä¸‹æ–‡æ¡£ï¼ˆä½¿ç”¨ {language} ç”Ÿæˆå…ƒæ•°æ®ï¼‰ï¼š

æºæ–‡ä»¶: {source}

---

{content}
```

**Step 3**: ä¿®æ”¹ `_process_document_combined` æ–¹æ³•

```python
# llm.py:_process_document_combined
async def _process_document_combined(
    self,
    markdown: str,
    source: str,
) -> DocumentProcessResult:
    # ... cache checks ...

    language = get_language_name(detect_language(markdown))
    truncated_content = self._smart_truncate(markdown, DEFAULT_MAX_CONTENT_CHARS)

    # è·å–åˆ†ç¦»çš„ system å’Œ user prompt
    system_prompt = self._prompt_manager.get_prompt("document_process_system")
    user_prompt = self._prompt_manager.get_prompt(
        "document_process_user",
        content=truncated_content,
        source=source,
        language=language,
    )

    # æ„å»ºæ¶ˆæ¯ï¼šåˆ†ç¦» system å’Œ user role
    messages = cast(
        list[ChatCompletionMessageParam],
        [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
    )

    # ... rest of the method ...
```

**Step 4**: å¢å¼º Pydantic model çš„ Field descriptions

```python
# llm.py:DocumentProcessResult
class DocumentProcessResult(BaseModel):
    """LLM document processing result."""

    cleaned_markdown: str = Field(
        description=(
            "æ ¼å¼ä¼˜åŒ–åçš„ Markdown æ–‡æ¡£å†…å®¹ã€‚"
            "åªåŒ…å«å®é™…çš„æ–‡æ¡£å†…å®¹ï¼Œä¸è¦åŒ…å«ä»»ä½•å¤„ç†æŒ‡ä»¤æˆ– prompt æ–‡æœ¬ã€‚"
        )
    )
    frontmatter: Frontmatter = Field(
        description="æ–‡æ¡£å…ƒæ•°æ®ï¼šæ ‡é¢˜ã€æ‘˜è¦ã€æ ‡ç­¾"
    )
```

**Step 5**: æ·»åŠ è¾“å‡ºéªŒè¯

```python
# llm.py: åœ¨ _process_document_combined è¿”å›å‰æ·»åŠ 
def _validate_no_prompt_leakage(self, cleaned: str, source: str) -> str:
    """æ£€æµ‹å¹¶å¤„ç† prompt æ³„æ¼ã€‚"""
    prompt_markers = [
        "## ä»»åŠ¡ 1:",
        "## ä»»åŠ¡ 2:",
        "ã€æ ¸å¿ƒåŸåˆ™ã€‘",
        "ã€æ¸…ç†è§„èŒƒã€‘",
        "è¯·å¤„ç†ä»¥ä¸‹",
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„",
    ]

    for marker in prompt_markers:
        if marker in cleaned:
            logger.warning(f"[{source}] Prompt leakage detected, attempting recovery")
            # å°è¯•æå– "---" åˆ†éš”ç¬¦ä¹‹åçš„å†…å®¹
            if "---" in cleaned:
                parts = cleaned.split("---", 2)
                if len(parts) > 2:
                    return parts[2].strip()
            raise ValueError("LLM returned prompt text in cleaned_markdown")

    return cleaned
```

### éªŒè¯æ–¹æ³•

```bash
markitai "https://stephango.com/concise" --preset rich --no-cache
# æ£€æŸ¥ output/*.llm.md ä¸åº”åŒ…å« "è¯·å¤„ç†ä»¥ä¸‹" "ã€æ ¸å¿ƒåŸåˆ™ã€‘" ç­‰ prompt æ–‡æœ¬
grep -l "è¯·å¤„ç†ä»¥ä¸‹\|ã€æ ¸å¿ƒåŸåˆ™ã€‘" output/*.llm.md  # åº”æ— åŒ¹é…
```

---

## Issue #3: x.com è¶…æ—¶åŠé”™è¯¯æ¶ˆæ¯ä¸å‡†ç¡®

### é—®é¢˜æè¿°

1. x.com ä½¿ç”¨ browser è·å–è¶…æ—¶ (30000ms)
2. è¶…æ—¶åé”™è¯¯æ¶ˆæ¯å»ºè®®"å®‰è£… agent-browser"ï¼Œä½† browser å®é™…å·²å®‰è£…ä¸”å°è¯•è¿‡

### æ·±åº¦æ ¹å› åˆ†æ

**è¶…æ—¶çš„æ ¹æœ¬åŸå› **ï¼š

1. **åçˆ¬è™«æ£€æµ‹**ï¼šx.com ä¸»åŠ¨æ£€æµ‹è‡ªåŠ¨åŒ–æµè§ˆå™¨
   - æ£€æµ‹ Playwright/Puppeteer ç‰¹å¾
   - è¦æ±‚ JavaScript åŠ¨æ€åŠ è½½å†…å®¹
   - å¯èƒ½æ˜¾ç¤ºéªŒè¯é¡µé¢

2. **ç­‰å¾…ç­–ç•¥ä¸å½“**ï¼š
   - å½“å‰ä½¿ç”¨ `wait_for: "domcontentloaded"`
   - x.com çš„æ ¸å¿ƒå†…å®¹é€šè¿‡ GraphQL API å¼‚æ­¥åŠ è½½
   - `domcontentloaded` è§¦å‘æ—¶å†…å®¹å¯èƒ½å°šæœªåŠ è½½

3. **è¶…æ—¶æ—¶é—´ä¸è¶³**ï¼š
   - é»˜è®¤ 30 ç§’å¯¹ç¤¾äº¤åª’ä½“ç«™ç‚¹ä¸å¤Ÿ
   - x.com å¯èƒ½éœ€è¦ 45-60 ç§’

**é”™è¯¯æ¶ˆæ¯ä¸å‡†ç¡®çš„åŸå› **ï¼š

```python
# fetch.py:1698-1704
if static_reason in CRITICAL_INVALID_REASONS:
    raise FetchError(
        f"URL requires browser rendering: {url}. "
        f"Reason: {static_reason}. "
        f"Please install agent-browser..."  # âŒ æœªåŒºåˆ†è¶…æ—¶æƒ…å†µ
    )
```

ä»£ç æ²¡æœ‰è¿½è¸ª browser æ˜¯å¦å·²å°è¯•è¿‡ä»¥åŠå¤±è´¥åŸå› ã€‚

### ä¿®å¤æ–¹æ¡ˆ

**æ–¹æ¡ˆ A: ä½¿ç”¨ Jina Reader API ä½œä¸ºé¦–é€‰ç­–ç•¥ï¼ˆæ¨èï¼‰**

Jina Reader å¯¹ç¤¾äº¤åª’ä½“æœ‰ç‰¹æ®Šä¼˜åŒ–ï¼Œæ— åçˆ¬è™«é—®é¢˜ã€‚

```python
# fetch.py: æ·»åŠ  Jina ç­–ç•¥ä¼˜å…ˆçº§
SOCIAL_MEDIA_JINA_PRIORITY = {
    "x.com",
    "twitter.com",
    "threads.net",
}

async def _fetch_with_fallback(
    url: str,
    config: FetchConfig,
    start_with_browser: bool = False,
) -> FetchResult:
    domain = extract_domain(url)

    # å¯¹äºç¤¾äº¤åª’ä½“ï¼Œä¼˜å…ˆä½¿ç”¨ Jina
    if domain in SOCIAL_MEDIA_JINA_PRIORITY and config.jina.api_key:
        try:
            result = await fetch_with_jina(url, config.jina)
            if result.content and not _is_invalid_content(result.content)[0]:
                return result
        except Exception as e:
            logger.debug(f"Jina fetch failed for {url}: {e}, falling back to browser")

    # ... ç»§ç»­åŸæœ‰çš„ browser/static ç­–ç•¥ ...
```

**æ–¹æ¡ˆ B: å¢åŠ ç¤¾äº¤åª’ä½“çš„è¶…æ—¶å’Œç­‰å¾…ç­–ç•¥**

```python
# fetch.py: ç¤¾äº¤åª’ä½“ç‰¹æ®Šé…ç½®
SOCIAL_MEDIA_BROWSER_CONFIG = {
    "x.com": {"timeout": 60000, "wait_for": "networkidle", "extra_wait_ms": 3000},
    "twitter.com": {"timeout": 60000, "wait_for": "networkidle", "extra_wait_ms": 3000},
    "instagram.com": {"timeout": 45000, "wait_for": "networkidle", "extra_wait_ms": 2000},
}

async def fetch_with_browser(url: str, ...) -> FetchResult:
    domain = extract_domain(url)

    # ä½¿ç”¨ç¤¾äº¤åª’ä½“ç‰¹æ®Šé…ç½®
    if domain in SOCIAL_MEDIA_BROWSER_CONFIG:
        override = SOCIAL_MEDIA_BROWSER_CONFIG[domain]
        timeout = override.get("timeout", timeout)
        wait_for = override.get("wait_for", wait_for)
        extra_wait_ms = override.get("extra_wait_ms", extra_wait_ms)

    # ... ç»§ç»­æ‰§è¡Œ ...
```

**æ–¹æ¡ˆ C: å®ç° Nitter fallbackï¼ˆå¤‡é€‰ï¼‰**

```python
# fetch.py: Nitter ä½œä¸º Twitter çš„ fallback
NITTER_INSTANCES = [
    "nitter.net",
    "nitter.poast.org",
    "nitter.privacydev.net",
]

def _convert_twitter_to_nitter(url: str) -> str:
    """Convert x.com/twitter.com URL to nitter instance."""
    parsed = urlparse(url)
    instance = random.choice(NITTER_INSTANCES)
    return f"https://{instance}{parsed.path}"

# åœ¨ browser è¶…æ—¶åå°è¯• nitter
if "x.com" in url or "twitter.com" in url:
    try:
        nitter_url = _convert_twitter_to_nitter(url)
        return await fetch_with_static(nitter_url)
    except Exception:
        pass  # nitter ä¹Ÿå¤±è´¥ï¼Œç»§ç»­åŸæœ‰é”™è¯¯å¤„ç†
```

**æ–¹æ¡ˆ D: ä¿®å¤é”™è¯¯æ¶ˆæ¯ï¼ˆå¿…é¡»ï¼‰**

```python
# fetch.py:_fetch_multi_source ä¸­è¿½è¸ª browser çŠ¶æ€
browser_attempted = False
browser_timed_out = False
browser_error_msg = ""

# åœ¨ browser å°è¯•åè®°å½•çŠ¶æ€
if browser_task and not browser_task.cancelled():
    browser_attempted = True
    try:
        browser_result = await browser_task
    except asyncio.TimeoutError:
        browser_timed_out = True
        browser_error_msg = f"Browser fetch timed out after {timeout}ms"
    except Exception as e:
        browser_error_msg = str(e)

# ä¿®æ”¹é”™è¯¯æ¶ˆæ¯
if static_reason in CRITICAL_INVALID_REASONS:
    if browser_timed_out:
        raise FetchError(
            f"URL requires browser rendering: {url}. "
            f"{browser_error_msg}. "
            f"Try: 1) Increase timeout with --fetch-timeout 60000, "
            f"2) Check network connectivity, "
            f"3) Use Jina API with --jina-api-key"
        )
    elif browser_attempted:
        raise FetchError(
            f"URL requires browser rendering: {url}. "
            f"Browser fetch failed: {browser_error_msg}"
        )
    else:
        raise FetchError(
            f"URL requires browser rendering: {url}. "
            f"Reason: {static_reason}. "
            f"Please install agent-browser: npm install -g agent-browser && agent-browser install"
        )
```

### æ¨èçš„å®æ–½ä¼˜å…ˆçº§

1. **ç«‹å³ä¿®å¤**ï¼šé”™è¯¯æ¶ˆæ¯ä¸å‡†ç¡®ï¼ˆæ–¹æ¡ˆ Dï¼‰
2. **çŸ­æœŸ**ï¼šå¯ç”¨ Jina API ä¼˜å…ˆç­–ç•¥ï¼ˆæ–¹æ¡ˆ Aï¼‰
3. **ä¸­æœŸ**ï¼šå¢åŠ ç¤¾äº¤åª’ä½“è¶…æ—¶é…ç½®ï¼ˆæ–¹æ¡ˆ Bï¼‰
4. **é•¿æœŸ**ï¼šå®ç° Nitter fallbackï¼ˆæ–¹æ¡ˆ Cï¼‰

### éªŒè¯æ–¹æ³•

```bash
# æµ‹è¯• x.comï¼Œåº”æ˜¾ç¤ºè¶…æ—¶é”™è¯¯è€Œéå®‰è£…æç¤º
markitai "https://x.com/user/status/123" --preset rich --no-cache
# æœŸæœ›: "Browser fetch timed out" æˆ– "Try Jina API"
# ä¸æœŸæœ›: "Please install agent-browser"
```

---

## Issue #4: max_tokens è¶…å‡º deepseek é™åˆ¶

### é—®é¢˜æè¿°

```
ERROR: Invalid max_tokens value, the valid range of max_tokens is [1, 8192]
```

### æ·±åº¦æ ¹å› åˆ†æ

**é—®é¢˜é“¾**ï¼š

1. `_get_router_primary_model()` è¿”å›é…ç½®ä¸­ç¬¬ä¸€ä¸ªæ¨¡å‹ (`gemini/gemini-2.5-flash-lite`)
2. ä»£ç åŸºäºè¯¥æ¨¡å‹è®¡ç®— `max_tokens`
3. Router å®é™…é€‰æ‹©äº† `openrouter/deepseek/deepseek-v3.2`
4. LiteLLM `get_model_info('deepseek/deepseek-v3.2')` è¿”å›é”™è¯¯çš„ `max_output_tokens=163840`
5. å®é™… API é™åˆ¶æ˜¯ `8192`
6. è¯·æ±‚è¢«æ‹’ç»

**LiteLLM æ¨¡å‹ä¿¡æ¯ä¸å‡†ç¡®**ï¼š

| æ¨¡å‹ | LiteLLM è¿”å›å€¼ | å®é™…é™åˆ¶ |
|------|---------------|----------|
| `deepseek/deepseek-v3.2` | 163840 | 8192 |
| `deepseek/deepseek-chat` | 8192 | 8192 |
| `openrouter/deepseek/deepseek-v3.2` | (æœªçŸ¥) | 8192 |

### ä¿®å¤æ–¹æ¡ˆ

**ç­–ç•¥ 1: æ¨¡å‹é™åˆ¶è¦†ç›–è¡¨ï¼ˆæ¨èï¼‰**

```python
# llm.py: å·²çŸ¥ LiteLLM ä¿¡æ¯ä¸å‡†ç¡®çš„æ¨¡å‹
MODEL_MAX_OUTPUT_OVERRIDES = {
    "deepseek/deepseek-v3.2": 8192,
    "openrouter/deepseek/deepseek-v3.2": 8192,
    "openrouter/deepseek/deepseek-chat": 8192,
}

def get_model_info_cached(model: str) -> dict[str, Any]:
    info = _cached_get_model_info(model)

    # åº”ç”¨å·²çŸ¥çš„è¦†ç›–
    if model in MODEL_MAX_OUTPUT_OVERRIDES:
        info = dict(info)  # åˆ›å»ºå‰¯æœ¬
        info["max_output_tokens"] = MODEL_MAX_OUTPUT_OVERRIDES[model]
        logger.debug(f"[ModelInfo] Applied override for {model}: max_output_tokens={info['max_output_tokens']}")

    return info
```

**ç­–ç•¥ 2: ä½¿ç”¨æ‰€æœ‰å¯èƒ½æ¨¡å‹çš„æœ€å°å€¼**

```python
# llm.py:_calculate_dynamic_max_tokens
def _calculate_dynamic_max_tokens(
    self, messages: list[Any], target_model_id: str | None = None
) -> int | None:
    # æ”¶é›†æ‰€æœ‰å¯èƒ½è¢«é€‰ä¸­çš„æ¨¡å‹çš„ max_output_tokens
    all_max_outputs = []
    for model_config in self.router.model_list:
        model_id = model_config.get("litellm_params", {}).get("model")
        if model_id:
            info = get_model_info_cached(model_id)
            max_out = info.get("max_output_tokens")
            if max_out:
                all_max_outputs.append(max_out)

    if not all_max_outputs:
        return None  # è®© LiteLLM å¤„ç†

    # ä½¿ç”¨æœ€å°å€¼ç¡®ä¿å…¼å®¹æ‰€æœ‰å¯èƒ½è¢«é€‰ä¸­çš„æ¨¡å‹
    max_output = min(all_max_outputs)
    logger.debug(f"[DynamicTokens] Using min max_output from all models: {max_output}")

    # ... ç»§ç»­è®¡ç®— ...
```

**ç­–ç•¥ 3: æ•è· max_tokens é”™è¯¯å¹¶é‡è¯•**

```python
# llm.py:_call_llm_with_retry ä¸­æ·»åŠ 
except litellm.BadRequestError as e:
    error_msg = str(e)
    if "max_tokens" in error_msg.lower() and "invalid" in error_msg.lower():
        # è§£æé”™è¯¯ä¸­çš„æœ‰æ•ˆèŒƒå›´
        import re
        match = re.search(r'\[(\d+),\s*(\d+)\]', error_msg)
        if match:
            valid_max = int(match.group(2))
            logger.warning(
                f"[LLM:{call_id}] max_tokens exceeded, retrying with {valid_max}"
            )
            # ç”¨æ›´å°çš„ max_tokens é‡è¯•
            return await self._call_llm_with_retry(
                model, messages, call_id, context, max_retries=0,
                max_tokens_override=valid_max
            )
    raise
```

### éªŒè¯æ–¹æ³•

```bash
markitai packages/markitai/tests/fixtures/file_example_XLSX_100.xlsx --preset rich --no-cache
grep "Invalid max_tokens" logs/markitai_*.log  # åº”æ— åŒ¹é…
```

---

## Issue #5: å›¾ç‰‡ä¸‹è½½å¤±è´¥ (å¤–éƒ¨èµ„æº)

### é—®é¢˜æè¿°

```
Failed to download image: https://yenwtime-1255970624.cos.ap-guangzhou.myqcloud.com/JPG/unit.jpg
```

### åˆ†æ

- COS bucket URL ä¸å¯è®¿é—®ï¼ˆå¯èƒ½å·²è¿‡æœŸæˆ–æƒé™é—®é¢˜ï¼‰
- **è¿™æ˜¯å¤–éƒ¨èµ„æºé—®é¢˜ï¼Œéä»£ç  bug**
- å½“å‰ä»£ç å·²æœ‰ fallback å¤„ç†ï¼Œå›¾ç‰‡ä¸‹è½½å¤±è´¥ä¸ä¼šé˜»æ–­æ•´ä½“æµç¨‹

### å¤„ç†

ä¸éœ€è¦ä»£ç ä¿®å¤ã€‚

---

## æ‰§è¡Œè®¡åˆ’

### Phase 1: Critical ä¿®å¤ï¼ˆå¹¶è¡Œæ‰§è¡Œï¼‰

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | ä¿®æ”¹æ–‡ä»¶ |
|------|--------|----------|
| Prompt æ‹†åˆ† system/user | P0 | `llm.py`, `prompts/*.md` |
| max_tokens è¦†ç›–è¡¨ | P0 | `llm.py` |
| é”™è¯¯æ¶ˆæ¯ä¿®å¤ | P1 | `fetch.py` |
| Terminal çª—å£éšè— | P1 | `fetch.py` |

### Phase 2: å¢å¼ºä¿®å¤

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | ä¿®æ”¹æ–‡ä»¶ |
|------|--------|----------|
| Jina API ä¼˜å…ˆç­–ç•¥ | P2 | `fetch.py` |
| ç¤¾äº¤åª’ä½“è¶…æ—¶é…ç½® | P2 | `fetch.py`, `constants.py` |
| Nitter fallback | P3 | `fetch.py` |

### Phase 3: éªŒè¯æµ‹è¯•

```bash
# å®Œæ•´æµ‹è¯•
markitai packages/markitai/tests/fixtures --no-cache --preset rich -o ./output-test --verbose

# æ£€æŸ¥é¡¹:
# - [ ] æ— å¯è§ Terminal çª—å£
# - [ ] .llm.md æ–‡ä»¶æ—  prompt æ³„æ¼
# - [ ] æ—  max_tokens é”™è¯¯
# - [ ] x.com è¶…æ—¶æ˜¾ç¤ºæ­£ç¡®é”™è¯¯æ¶ˆæ¯
```

---

## å·²å®Œæˆçš„ä¿®å¤ï¼ˆå†å²ï¼‰

| é—®é¢˜ | ä¿®å¤çŠ¶æ€ |
|------|----------|
| agent-browser Windows æ‰§è¡Œå¤±è´¥ | **å·²ä¿®å¤** - ä½¿ç”¨ native exe |
| PDF å›¾ç‰‡è·¯å¾„é”™è¯¯ | **å·²ä¿®å¤** - ä½¿ç”¨ `as_posix()` |
| Alt text æ¡ä»¶é€»è¾‘é”™è¯¯ | **å·²ä¿®å¤** - `alt_enabled or desc_enabled` |
| JS ç«™ç‚¹é™é»˜å›é€€ | **å·²ä¿®å¤** - ä¸¥æ ¼æ¨¡å¼æŠ¥é”™ |
| Page marker æ¢å¤é€»è¾‘ | **å·²ä¿®å¤** - å°Šé‡ LLM ç»“æœ |
| Symlink æµ‹è¯•å¤±è´¥ | **å·²ä¿®å¤** - `@requires_symlink` è£…é¥°å™¨ |

---

## å¤‡æ³¨

- ä¿®å¤é¡ºåºæŒ‰ä¼˜å…ˆçº§æ‰§è¡Œ
- P0 ä»»åŠ¡å¹¶è¡Œæ‰§è¡Œ
- æ¯ä¸ªä¿®å¤å®Œæˆåè¿è¡Œ ruff/pyright éªŒè¯
- å®Œæˆåæ‰‹åŠ¨æäº¤

---
---

# Windows æ€§èƒ½ä¼˜åŒ–ä»»åŠ¡

> åŸºäº `docs/reference/windows-opt-1.md` æ·±åº¦åˆ†ææŠ¥å‘Š
> åˆ›å»ºæ—¶é—´: 2026-01-27
> é¢„æœŸæ”¶ç›Š: Windows æ‰¹å¤„ç†æ€§èƒ½æå‡ 2-4 å€

---

## ä¼˜åŒ–ä»»åŠ¡æ€»è§ˆ

| # | ä»»åŠ¡ | éš¾åº¦ | ä¼˜å…ˆçº§ | é¢„æœŸæ”¶ç›Š | çŠ¶æ€ |
|---|------|------|--------|----------|------|
| W1 | çº¿ç¨‹æ± é…ç½®è°ƒä¼˜ | â­ | ğŸ”´ High | -10~20% åˆ‡æ¢å¼€é”€ | âœ… å·²å®Œæˆ |
| W2 | ONNX Runtime å…¨å±€å•ä¾‹ + é¢„çƒ­ | â­â­ | ğŸ”´ High | -3~8s é¦–æ¬¡è°ƒç”¨ | âœ… å·²å®Œæˆ |
| W3 | å›¾åƒå¤„ç† OpenCV ä¼˜åŒ– | â­â­ | ğŸŸ¡ Medium | CPU å¤„ç†æé€Ÿ 20-40% | âœ… å·²å®Œæˆ |
| W4 | asyncio å­è¿›ç¨‹å‘½ä»¤æ‰¹é‡åŒ– | â­â­ | ğŸŸ¡ Medium | æ¯é¡µé¢ -200~500ms | âœ… å·²å®Œæˆ |
| W5 | LibreOffice UNO å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼ | â­â­â­â­ | ğŸŸ¢ Low | æ¯æ–‡ä»¶ -2~3s | â¸ï¸ æ¨è¿Ÿ |

---

## W1: çº¿ç¨‹æ± é…ç½®è°ƒä¼˜

### é—®é¢˜èƒŒæ™¯

**ä½ç½®**: `packages/markitai/src/markitai/utils/executor.py` L14-58

å½“å‰é…ç½®:
```python
_CONVERTER_MAX_WORKERS = min(os.cpu_count() or 4, 8)
```

Windows çº¿ç¨‹ä¸Šä¸‹æ–‡åˆ‡æ¢å¼€é”€çº¦ 2-8 Î¼sï¼ˆLinux ä¸º 1-3 Î¼sï¼‰ï¼Œé«˜çº¿ç¨‹æ•°ä¸‹å·®å¼‚ç´¯ç§¯æ˜æ˜¾ã€‚

### å®æ–½æ–¹æ¡ˆ

**æ–‡ä»¶**: `packages/markitai/src/markitai/utils/executor.py`

```python
import os
import platform

def _get_optimal_workers():
    cpu_count = os.cpu_count() or 4
    if platform.system() == "Windows":
        # Windows: é™ä½é»˜è®¤å€¼ï¼Œå‡å°‘çº¿ç¨‹åˆ‡æ¢å¼€é”€
        return min(cpu_count, 4)
    else:
        # Linux/macOS: å¯ä»¥ä½¿ç”¨æ›´é«˜å¹¶å‘
        return min(cpu_count, 8)

_CONVERTER_MAX_WORKERS = _get_optimal_workers()
```

### éªŒè¯æ–¹æ³•

```bash
# è¿è¡Œæ‰¹å¤„ç†æµ‹è¯•ï¼Œå¯¹æ¯”ä¿®æ”¹å‰åè€—æ—¶
markitai packages/markitai/tests/fixtures --preset rich -o ./output-perf-test --verbose
```

### é¢„æœŸæ”¶ç›Š

- å‡å°‘çº¿ç¨‹åˆ‡æ¢å¼€é”€ 10-20%
- Windows ä¸Šæ›´ç¨³å®šçš„å¹¶å‘æ€§èƒ½

---

## W2: ONNX Runtime å…¨å±€å•ä¾‹ + é¢„çƒ­

### é—®é¢˜èƒŒæ™¯

**ä½ç½®**: `packages/markitai/src/markitai/ocr.py` L39-85

RapidOCR åŸºäº ONNX Runtimeï¼Œå†·å¯åŠ¨å»¶è¿Ÿæºäº:
1. DLL åŠ è½½å¼€é”€ï¼ˆWindows ç‰¹æœ‰ï¼‰
2. DirectML/CUDA åˆå§‹åŒ–
3. æ¨¡å‹åŠ è½½å’Œå›¾ä¼˜åŒ–

å®æµ‹å½±å“: CPU æ¨¡å¼ 1-3sï¼ŒDirectML 3-8sï¼ŒCUDA 5-15s

### å®æ–½æ–¹æ¡ˆ

**æ–‡ä»¶**: `packages/markitai/src/markitai/ocr.py`

```python
import threading
import numpy as np

class OCRProcessor:
    _global_engine = None
    _init_lock = threading.Lock()

    @classmethod
    def get_shared_engine(cls, config: OCRConfig | None = None):
        """Get or create global singleton engine (thread-safe)."""
        if cls._global_engine is None:
            with cls._init_lock:
                if cls._global_engine is None:
                    cls._global_engine = cls._create_engine_impl(config)
        return cls._global_engine

    @classmethod
    def preheat(cls, config: OCRConfig | None = None):
        """Preheat engine at application startup."""
        engine = cls.get_shared_engine(config)
        # Execute dummy inference to complete GPU compilation
        dummy_image = np.zeros((100, 100, 3), dtype=np.uint8)
        try:
            engine(dummy_image)
        except Exception:
            pass  # Ignore errors from dummy image
        return engine

    @property
    def engine(self):
        """Use shared engine instead of instance engine."""
        return self.get_shared_engine(self.config)
```

### é¢å¤–ä¿®æ”¹

**æ–‡ä»¶**: `packages/markitai/src/markitai/cli.py` æˆ– `batch.py`

åœ¨æ‰¹å¤„ç†æ¨¡å¼å…¥å£æ·»åŠ é¢„çƒ­è°ƒç”¨:
```python
if batch_mode and ocr_enabled:
    from markitai.ocr import OCRProcessor
    OCRProcessor.preheat()
```

### éªŒè¯æ–¹æ³•

```bash
# é¦–æ¬¡ OCR è°ƒç”¨ä¸åº”æœ‰æ˜æ˜¾å»¶è¿Ÿ
markitai packages/markitai/tests/fixtures/image.png --preset rich --verbose
# æ£€æŸ¥æ—¥å¿—ä¸­ OCR åˆå§‹åŒ–æ—¶é—´
```

### é¢„æœŸæ”¶ç›Š

- æ¶ˆé™¤é¦–æ¬¡è°ƒç”¨ 1-8 ç§’å»¶è¿Ÿ
- æ‰¹å¤„ç†æ—¶æ‰€æœ‰æ–‡ä»¶å…±äº«åŒä¸€å¼•æ“

---

## W3: å›¾åƒå¤„ç† OpenCV ä¼˜åŒ–

### é—®é¢˜èƒŒæ™¯

**ä½ç½®**: `packages/markitai/src/markitai/image.py` L37-95 (`_compress_image_worker`)

Pillow åœ¨ Python å±‚å¤„ç†ï¼Œå— GIL é™åˆ¶ã€‚OpenCV åœ¨ C++ å±‚é‡Šæ”¾ GILï¼Œæ›´é€‚åˆå¤šçº¿ç¨‹ã€‚

### å®æ–½æ–¹æ¡ˆ

#### Step 1: æ·»åŠ ä¾èµ–

**æ–‡ä»¶**: `packages/markitai/pyproject.toml`

```toml
dependencies = [
    # ... existing deps ...
    "opencv-python>=4.8.0",
]
```

#### Step 2: å®ç° OpenCV å‹ç¼©å‡½æ•°

**æ–‡ä»¶**: `packages/markitai/src/markitai/image.py`

```python
import cv2
import numpy as np

def _compress_image_cv2(
    image_data: bytes,
    quality: int,
    max_size: tuple[int, int],
    output_format: str = "JPEG",
) -> tuple[bytes, int, int]:
    """Compress image using OpenCV (releases GIL in C++ layer)."""
    # Decode
    nparr = np.frombuffer(image_data, np.uint8)
    img = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
    if img is None:
        raise ValueError("Failed to decode image")

    h, w = img.shape[:2]

    # Resize if needed
    if w > max_size[0] or h > max_size[1]:
        scale = min(max_size[0] / w, max_size[1] / h)
        new_w, new_h = int(w * scale), int(h * scale)
        img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_LANCZOS4)
        w, h = new_w, new_h

    # Encode
    if output_format.upper() == "JPEG":
        encode_param = [cv2.IMWRITE_JPEG_QUALITY, quality]
        _, buffer = cv2.imencode('.jpg', img, encode_param)
    elif output_format.upper() == "PNG":
        # PNG compression level 0-9, map quality 0-100 to 9-0
        compression = max(0, min(9, 9 - quality // 11))
        encode_param = [cv2.IMWRITE_PNG_COMPRESSION, compression]
        _, buffer = cv2.imencode('.png', img, encode_param)
    elif output_format.upper() == "WEBP":
        encode_param = [cv2.IMWRITE_WEBP_QUALITY, quality]
        _, buffer = cv2.imencode('.webp', img, encode_param)
    else:
        raise ValueError(f"Unsupported format: {output_format}")

    return buffer.tobytes(), w, h
```

#### Step 3: ä¿®æ”¹ worker å‡½æ•°

```python
def _compress_image_worker(...):
    # ä¼˜å…ˆä½¿ç”¨ OpenCVï¼Œå¤±è´¥æ—¶å›é€€åˆ° Pillow
    try:
        return _compress_image_cv2(image_data, quality, max_size, output_format)
    except Exception:
        return _compress_image_pillow(image_data, quality, max_size, output_format)
```

### éªŒè¯æ–¹æ³•

```bash
# è¿è¡Œå›¾åƒå‹ç¼©æ€§èƒ½æµ‹è¯•
python -c "
from markitai.image import _compress_image_cv2
import time
with open('test.jpg', 'rb') as f:
    data = f.read()
start = time.time()
for _ in range(100):
    _compress_image_cv2(data, 85, (1920, 1080))
print(f'OpenCV: {time.time()-start:.2f}s')
"
```

### é¢„æœŸæ”¶ç›Š

- CPU å¯†é›†å‹å›¾åƒå¤„ç†æé€Ÿ 20-40%
- å¤šçº¿ç¨‹åœºæ™¯ä¸‹æ•ˆæœæ›´æ˜æ˜¾

---

## W4: asyncio å­è¿›ç¨‹å‘½ä»¤æ‰¹é‡åŒ–

### é—®é¢˜èƒŒæ™¯

**ä½ç½®**: `packages/markitai/src/markitai/fetch.py` L645-686

æ¯æ¬¡ `agent-browser` å‘½ä»¤è°ƒç”¨å¢åŠ çº¦ 50-100ms å¼€é”€ã€‚URL æ‰¹é‡æŠ“å–æ—¶å¤šæ¬¡è°ƒç”¨ï¼ˆopen, wait, snapshot, getï¼‰å½±å“ç´¯ç§¯ã€‚

### å®æ–½æ–¹æ¡ˆ

**æ–‡ä»¶**: `packages/markitai/src/markitai/fetch.py`

```python
async def _run_agent_browser_batch(
    session: str,
    commands: list[tuple[str, list[str]]],  # [(command, args), ...]
    timeout_seconds: float,
) -> list[tuple[bytes, bytes, int]]:
    """Execute multiple agent-browser commands in batch."""
    # æ–¹æ¡ˆ A: ä½¿ç”¨ agent-browser çš„ batch/script åŠŸèƒ½ï¼ˆå¦‚æœæ”¯æŒï¼‰
    # æ–¹æ¡ˆ B: åˆå¹¶ä¸ºå•ä¸ª shell è„šæœ¬æ‰§è¡Œ
    # æ–¹æ¡ˆ C: ä½¿ç”¨ agent-browser çš„æŒä¹…è¿æ¥æ¨¡å¼

    # å½“å‰å®ç°: å¤ç”¨ sessionï¼Œå‡å°‘æµè§ˆå™¨å¯åŠ¨å¼€é”€
    results = []
    for cmd, args in commands:
        full_args = ["--session", session, cmd] + args
        result = await _run_agent_browser_command(full_args, timeout_seconds)
        results.append(result)
    return results
```

**ä¼˜åŒ– session å¤ç”¨**:

```python
async def fetch_page_with_browser(url: str, ...) -> BrowserFetchResult:
    session = f"markitai-{hash(url) % 10000}"  # ä½¿ç”¨å›ºå®š session å

    # æ‰¹é‡æ‰§è¡Œå‘½ä»¤
    commands = [
        ("open", [url]),
        ("wait", ["--load", "domcontentloaded"]),
        ("snapshot", ["-c", "--json"]),
        ("get", ["title"]),
    ]

    results = await _run_agent_browser_batch(session, commands, timeout)
    # ... parse results ...
```

### éªŒè¯æ–¹æ³•

```bash
# æ‰¹é‡å¤„ç† URLï¼Œå¯¹æ¯”ä¿®æ”¹å‰åè€—æ—¶
markitai "https://example.com" "https://httpbin.org/html" --preset rich --verbose
```

### é¢„æœŸæ”¶ç›Š

- å‡å°‘ 3-5 æ¬¡å­è¿›ç¨‹åˆ›å»º
- æ¯é¡µé¢èŠ‚çœ 200-500ms

---

## W5: LibreOffice UNO å®ˆæŠ¤è¿›ç¨‹æ¨¡å¼

### é—®é¢˜èƒŒæ™¯

**ä½ç½®**:
- `packages/markitai/src/markitai/converter/office.py` L378-402
- `packages/markitai/src/markitai/converter/legacy.py` L517-531

æ¯æ¬¡è°ƒç”¨ LibreOffice éœ€è¦:
1. å¯åŠ¨ `soffice.exe`ï¼ˆ2-3sï¼‰
2. åŠ è½½ UNO è¿è¡Œæ—¶
3. åˆå§‹åŒ–æ–‡æ¡£å¤„ç†æ¡†æ¶

### å®æ–½æ–¹æ¡ˆï¼ˆéœ€è¯„ä¼°å¯è¡Œæ€§ï¼‰

#### Step 1: å¯åŠ¨ LibreOffice å®ˆæŠ¤è¿›ç¨‹

```bash
# Windows
soffice.exe --accept="socket,host=localhost,port=2002;urp;" --headless

# Linux
soffice --accept="socket,host=localhost,port=2002;urp;" --headless &
```

#### Step 2: å®ç° UNO è¿æ¥æ± 

**æ–°æ–‡ä»¶**: `packages/markitai/src/markitai/utils/libreoffice_pool.py`

```python
import uno
from com.sun.star.beans import PropertyValue

class LibreOfficePool:
    def __init__(self, port: int = 2002):
        self._port = port
        self._desktop = None
        self._connected = False

    def connect(self):
        """Connect to running LibreOffice instance."""
        if self._connected:
            return

        local_context = uno.getComponentContext()
        resolver = local_context.ServiceManager.createInstanceWithContext(
            "com.sun.star.bridge.UnoUrlResolver", local_context
        )
        ctx = resolver.resolve(
            f"uno:socket,host=localhost,port={self._port};urp;StarOffice.ComponentContext"
        )
        smgr = ctx.ServiceManager
        self._desktop = smgr.createInstanceWithContext(
            "com.sun.star.frame.Desktop", ctx
        )
        self._connected = True

    def convert_to_pdf(self, input_path: str, output_path: str) -> bool:
        """Convert document to PDF using UNO API."""
        if not self._connected:
            self.connect()

        url = uno.systemPathToFileUrl(input_path)
        doc = self._desktop.loadComponentFromURL(url, "_blank", 0, ())

        filter_props = (
            PropertyValue("FilterName", 0, "writer_pdf_Export", 0),
        )
        output_url = uno.systemPathToFileUrl(output_path)
        doc.storeToURL(output_url, filter_props)
        doc.close(True)
        return True

    def close(self):
        """Close connection."""
        if self._desktop:
            try:
                self._desktop.terminate()
            except Exception:
                pass
        self._connected = False
```

### è¯„ä¼°è¦ç‚¹

1. **å¯è¡Œæ€§**: UNO API åœ¨ Windows ä¸Šæ˜¯å¦ç¨³å®šï¼Ÿ
2. **ä¾èµ–**: éœ€è¦é¢å¤–å®‰è£… `uno` åŒ…ï¼Ÿï¼ˆLibreOffice è‡ªå¸¦ Python ç»‘å®šï¼‰
3. **å¤æ‚åº¦**: è¿›ç¨‹ç®¡ç†ã€è¿æ¥é‡è¯•ã€é”™è¯¯æ¢å¤
4. **æ”¶ç›Š**: æ‰¹å¤„ç† 10+ æ–‡ä»¶æ—¶æ˜¾è‘—ï¼Œå•æ–‡ä»¶æ”¶ç›Šæœ‰é™

### è¯„ä¼°ç»“è®ºï¼ˆ2026-01-27ï¼‰

**å†³å®šï¼šæ¨è¿Ÿåˆ°åç»­ç‰ˆæœ¬å®ç°**

**åŸå› ï¼š**

1. **ä¾èµ–é—®é¢˜**ï¼š`uno` æ¨¡å—æ˜¯ LibreOffice è‡ªå¸¦çš„ Python ç»‘å®šï¼Œæ— æ³•é€šè¿‡ pip å®‰è£…ã€‚éœ€è¦é…ç½® `PYTHONPATH` æŒ‡å‘ LibreOffice å®‰è£…ç›®å½•ä¸­çš„ Python åº“ï¼Œæˆ–ä½¿ç”¨ LibreOffice è‡ªå¸¦çš„ Python è§£é‡Šå™¨ã€‚è¿™å¢åŠ äº†éƒ¨ç½²å¤æ‚åº¦ã€‚

2. **å®ˆæŠ¤è¿›ç¨‹ç®¡ç†**ï¼šéœ€è¦å®ç°ï¼š
   - ç¨‹åºå¯åŠ¨æ—¶è‡ªåŠ¨å¯åŠ¨ LibreOffice å®ˆæŠ¤è¿›ç¨‹
   - ç¨‹åºé€€å‡ºæ—¶æ¸…ç†å®ˆæŠ¤è¿›ç¨‹
   - å®ˆæŠ¤è¿›ç¨‹å´©æºƒæ—¶è‡ªåŠ¨é‡å¯
   - è¶…æ—¶å’Œå¥åº·æ£€æŸ¥æœºåˆ¶

3. **å¹¶å‘è®¿é—®**ï¼šUNO è¿æ¥ä¸æ˜¯çº¿ç¨‹å®‰å…¨çš„ï¼Œéœ€è¦å®ç°ï¼š
   - è¿æ¥æ± ç®¡ç†
   - è¯·æ±‚æ’é˜Ÿæˆ–åºåˆ—åŒ–
   - è¿æ¥å¤±æ•ˆæ£€æµ‹å’Œé‡å»º

4. **è·¨å¹³å°å·®å¼‚**ï¼šWindowsã€Linuxã€macOS ä¸Šçš„ LibreOffice å®‰è£…è·¯å¾„å’Œ Python ç»‘å®šä½ç½®ä¸åŒï¼Œéœ€è¦åˆ†åˆ«å¤„ç†ã€‚

5. **æŠ•å…¥äº§å‡ºæ¯”**ï¼šå½“å‰å­è¿›ç¨‹æ¨¡å¼è™½ç„¶æ¯æ¬¡å¯åŠ¨æœ‰ 2-3s å¼€é”€ï¼Œä½†å®ç°ç®€å•å¯é ã€‚UNO æ¨¡å¼çš„å¤æ‚åº¦ï¼ˆâ­â­â­â­ï¼‰ä¸é¢„æœŸæ”¶ç›Šä¸æˆæ­£æ¯”ã€‚

**æ›¿ä»£æ–¹æ¡ˆ**ï¼š
- å½“å‰å·²é€šè¿‡ W1-W4 ä¼˜åŒ–è·å¾—æ˜¾è‘—æ€§èƒ½æå‡
- å¦‚éœ€è¿›ä¸€æ­¥ä¼˜åŒ– LibreOffice æ€§èƒ½ï¼Œå¯è€ƒè™‘ä½¿ç”¨ Docker å®¹å™¨é¢„çƒ­ LibreOffice å®ä¾‹

### éªŒè¯æ–¹æ³•ï¼ˆä»…ä¾›å‚è€ƒï¼‰

```bash
# å¯åŠ¨ LibreOffice å®ˆæŠ¤è¿›ç¨‹
soffice.exe --accept="socket,host=localhost,port=2002;urp;" --headless

# æµ‹è¯• UNO è¿æ¥
python -c "
from markitai.utils.libreoffice_pool import LibreOfficePool
pool = LibreOfficePool()
pool.connect()
pool.convert_to_pdf('test.docx', 'test.pdf')
"
```

### é¢„æœŸæ”¶ç›Š

- æ¯æ–‡ä»¶èŠ‚çœ 2-3 ç§’å¯åŠ¨æ—¶é—´
- æ‰¹å¤„ç† 10+ æ–‡ä»¶æ—¶æé€Ÿæ˜¾è‘—

---

## å®æ–½è®¡åˆ’

### Phase 1: å¿«é€Ÿä¼˜åŒ–ï¼ˆç®€å•å®ç°ï¼‰

| åºå· | ä»»åŠ¡ | æ–‡ä»¶ | éš¾åº¦ |
|------|------|------|------|
| 1.1 | W1 çº¿ç¨‹æ± é…ç½®è°ƒä¼˜ | `utils/executor.py` | â­ |
| 1.2 | W2 ONNX å…¨å±€å•ä¾‹ | `ocr.py` | â­â­ |
| 1.3 | W2 ONNX é¢„çƒ­è°ƒç”¨ | `cli.py` / `batch.py` | â­ |

### Phase 2: ä¾èµ–å‡çº§ï¼ˆOpenCV é›†æˆï¼‰

| åºå· | ä»»åŠ¡ | æ–‡ä»¶ | éš¾åº¦ |
|------|------|------|------|
| 2.1 | æ·»åŠ  opencv-python ä¾èµ– | `pyproject.toml` | â­ |
| 2.2 | W3 å®ç° OpenCV å‹ç¼© | `image.py` | â­â­ |
| 2.3 | W3 worker å‡½æ•°åˆ‡æ¢ | `image.py` | â­ |

### Phase 3: æµç¨‹ä¼˜åŒ–ï¼ˆå­è¿›ç¨‹æ‰¹é‡åŒ–ï¼‰

| åºå· | ä»»åŠ¡ | æ–‡ä»¶ | éš¾åº¦ |
|------|------|------|------|
| 3.1 | W4 agent-browser å‘½ä»¤æ‰¹é‡åŒ– | `fetch.py` | â­â­ |
| 3.2 | W4 session å¤ç”¨ä¼˜åŒ– | `fetch.py` | â­ |

### Phase 4: é«˜çº§ä¼˜åŒ–ï¼ˆå¾…è¯„ä¼°ï¼‰

| åºå· | ä»»åŠ¡ | æ–‡ä»¶ | éš¾åº¦ |
|------|------|------|------|
| 4.1 | W5 è¯„ä¼° UNO å¯è¡Œæ€§ | - | â­â­ |
| 4.2 | W5 å®ç° LibreOffice è¿æ¥æ±  | `utils/libreoffice_pool.py` | â­â­â­â­ |
| 4.3 | W5 é›†æˆåˆ° converter | `converter/office.py`, `converter/legacy.py` | â­â­â­ |

---

## éªŒæ”¶æ ‡å‡†

### æ€§èƒ½æŒ‡æ ‡

```bash
# åŸºå‡†æµ‹è¯•å‘½ä»¤
markitai packages/markitai/tests/fixtures --preset rich -o ./output-benchmark --verbose

# å¯¹æ¯”æŒ‡æ ‡:
# - æ€»å¤„ç†æ—¶é—´
# - OCR é¦–æ¬¡è°ƒç”¨å»¶è¿Ÿ
# - å›¾ç‰‡å‹ç¼©è€—æ—¶
# - URL æŠ“å–è€—æ—¶
```

### æ£€æŸ¥é¡¹

- [x] Windows çº¿ç¨‹æ± é»˜è®¤ max_workers=4
- [x] OCR å¼•æ“å…¨å±€å•ä¾‹ï¼Œé¦–æ¬¡è°ƒç”¨æ— æ˜æ˜¾å»¶è¿Ÿ
- [x] å›¾ç‰‡å‹ç¼©ä½¿ç”¨ OpenCV
- [x] agent-browser å‘½ä»¤å¤ç”¨ session
- [x] æ— æ–°å¢ bug æˆ–å›å½’ï¼ˆ484 passed, 8 skippedï¼‰
- [x] ruff/pyright æ£€æŸ¥é€šè¿‡

---

## å®Œæˆè®°å½•

### 2026-01-27 Windows æ€§èƒ½ä¼˜åŒ–å®Œæˆ

**å®ç°å†…å®¹ï¼š**

1. **W1 çº¿ç¨‹æ± é…ç½®** (`utils/executor.py`)
   - æ–°å¢ `_get_optimal_workers()` å‡½æ•°
   - Windows é™åˆ¶ max_workers=4ï¼ŒLinux/macOS é™åˆ¶ max_workers=8

2. **W2 ONNX Runtime å•ä¾‹ + é¢„çƒ­** (`ocr.py`, `batch.py`)
   - æ–°å¢ `_global_engine`ã€`_global_config` ç±»å˜é‡
   - æ–°å¢ `get_shared_engine()` ç±»æ–¹æ³•ï¼ˆåŒé‡æ£€æŸ¥é”å®šï¼‰
   - æ–°å¢ `preheat()` ç±»æ–¹æ³•ï¼ˆæ‰§è¡Œ dummy inference é¢„çƒ­ï¼‰
   - æ–°å¢ `_create_engine_impl()` ç±»æ–¹æ³•
   - `batch.py` æ‰¹å¤„ç†å…¥å£æ·»åŠ  OCR é¢„çƒ­è°ƒç”¨

3. **W3 OpenCV å›¾åƒå‹ç¼©** (`image.py`, `pyproject.toml`)
   - æ–°å¢ `opencv-python>=4.8.0` ä¾èµ–
   - æ–°å¢ `_compress_image_cv2()` å‡½æ•°
   - é‡å‘½ååŸå‡½æ•°ä¸º `_compress_image_pillow()`
   - `_compress_image_worker()` ä¼˜å…ˆä½¿ç”¨ OpenCVï¼Œå¤±è´¥å›é€€ Pillow

4. **W4 asyncio å­è¿›ç¨‹æ‰¹é‡åŒ–** (`fetch.py`)
   - æ–°å¢ `_get_effective_agent_browser_args()` å‡½æ•°
   - æ–°å¢ `_run_agent_browser_batch()` å‡½æ•°
   - æ–°å¢ `_url_to_session_id()` å‡½æ•°ï¼ˆç¨³å®š session ID ç”Ÿæˆï¼‰

5. **W5 LibreOffice UNO å®ˆæŠ¤è¿›ç¨‹** - è¯„ä¼°åæ¨è¿Ÿåˆ°æœªæ¥ç‰ˆæœ¬

**å•å…ƒæµ‹è¯•ï¼š**

- `test_executor.py`: æ–°å¢ `TestGetOptimalWorkers` æµ‹è¯•ç±»ï¼ˆ5 ä¸ªæµ‹è¯•ç”¨ä¾‹ï¼‰
- `test_ocr.py`: æ–°å¢ `TestOCRProcessorSingleton`ã€`TestOCRProcessorPreheat` æµ‹è¯•ç±»
- `test_image.py`: æ–°å¢ `TestCompressImageWorkerFunctions` æµ‹è¯•ç±»
- `test_fetch.py`: æ–°å¢ `TestUrlToSessionId`ã€`TestGetEffectiveAgentBrowserArgs` æµ‹è¯•ç±»

**ä»£ç è´¨é‡ï¼š**

- ruff: All checks passed!
- pyright: 0 errors, 0 warnings
- pytest: 484 passed, 8 skipped

### 2026-01-27 Bug ä¿®å¤ï¼ˆç¬¬äºŒæ‰¹ï¼‰

**é—®é¢˜åˆ†æï¼š**

| # | é—®é¢˜ | æ ¹å›  | çŠ¶æ€ |
|---|------|------|------|
| 1 | ç»ˆç«¯çª—å£å¼¹å‡º (chrome-headless-shell.exe) | `verify_agent_browser_ready` ä½¿ç”¨ `subprocess.run()` æœªè®¾ç½® `CREATE_NO_WINDOW` | âœ… å·²ä¿®å¤ |
| 2 | agent-browser å¯åŠ¨å»¶è¿Ÿ 70s | `open about:blank` æµ‹è¯•è¶…æ—¶ 30s | âœ… å·²ä¿®å¤ |
| 3 | PDF LLM å¢å¼ºå¤±è´¥ (max_tokens è¶…é™) | Router é€‰æ‹© deepseek ä½† max_tokens åŸºäº gemini è®¡ç®— | âœ… å·²ä¿®å¤ |
| 4 | x.com è¶…æ—¶ | ä»£ç†æœªé…ç½® (ä¸­å›½å¤§é™†ç¯å¢ƒ) | âš ï¸ éœ€é…ç½® |
| 5 | URL screenshot å¤±è´¥ | browser è¶…æ—¶å¯¼è‡´ | âš ï¸ éœ€é…ç½® |

**ä¿®å¤å†…å®¹ï¼š**

1. **ç»ˆç«¯çª—å£éšè—** (`fetch.py`)
   - `verify_agent_browser_ready` çš„ `subprocess.run()` æ·»åŠ  `creationflags=CREATE_NO_WINDOW`
   - ç»Ÿä¸€ä½¿ç”¨ `run_kwargs` å­—å…¸ä¼ é€’å‚æ•°

2. **å¯åŠ¨å»¶è¿Ÿä¼˜åŒ–** (`fetch.py`)
   - `open about:blank` æµ‹è¯•è¶…æ—¶ä» 30s æ”¹ä¸º 10s
   - å‡å°‘å¯åŠ¨é˜»å¡æ—¶é—´

3. **max_tokens å…¼å®¹æ€§ä¿®å¤** (`llm.py`)
   - `_calculate_dynamic_max_tokens()` æ–°å¢ `router` å‚æ•°
   - å½“ä½¿ç”¨ Router æ—¶ï¼Œè·å–æ‰€æœ‰æ¨¡å‹ä¸­**æœ€å°çš„** `max_output_tokens`
   - ç¡®ä¿ä¸ Router å¯èƒ½é€‰æ‹©çš„ä»»ä½•æ¨¡å‹å…¼å®¹
   - æ›´æ–°æ‰€æœ‰è°ƒç”¨ç‚¹ï¼š
     - `_analyze_images_batch_instructor()`
     - `_analyze_single_image_instructor()`
     - `_analyze_single_image_json_mode()`
     - `enhance_url_with_vision()`
     - `_enhance_with_frontmatter()`

4. **ä»£ç†è‡ªåŠ¨æ£€æµ‹** (`fetch.py`) - **æ–°å¢åŠŸèƒ½**
   - æ–°å¢ `_detect_proxy()` å‡½æ•°ï¼Œè‡ªåŠ¨æ£€æµ‹ä»£ç†è®¾ç½®
   - æ£€æµ‹é¡ºåºï¼šç¯å¢ƒå˜é‡ â†’ æ¢æµ‹æœ¬åœ°å¸¸è§ä»£ç†ç«¯å£
   - æ”¯æŒçš„ç¯å¢ƒå˜é‡ï¼š`HTTPS_PROXY`, `HTTP_PROXY`, `ALL_PROXY`
   - æ¢æµ‹ç«¯å£ï¼š7890 (Clash), 10808 (V2Ray), 1080 (SOCKS5), 8080, 8118, 9050
   - æ–°å¢ `get_proxy_for_url()` å‡½æ•°ï¼Œä¸ºéœ€è¦ä»£ç†çš„ URL è¿”å›ä»£ç†
   - `_get_jina_client()` è‡ªåŠ¨åº”ç”¨æ£€æµ‹åˆ°çš„ä»£ç†
   - `_run_agent_browser_command()` è‡ªåŠ¨è®¾ç½®ä»£ç†ç¯å¢ƒå˜é‡ç»™ Playwright

**ä»£ç†è‡ªåŠ¨æ£€æµ‹è¯´æ˜ï¼š**

ç¨‹åºç°åœ¨ä¼šè‡ªåŠ¨æ£€æµ‹ä»£ç†è®¾ç½®ï¼š

1. **ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡**ï¼š`HTTPS_PROXY`, `HTTP_PROXY`, `ALL_PROXY`
2. **è‡ªåŠ¨æ¢æµ‹æœ¬åœ°ä»£ç†**ï¼šæ¢æµ‹ 127.0.0.1 ä¸Šçš„å¸¸è§ä»£ç†ç«¯å£
   - Clash: 7890, 7891
   - V2Ray: 10808, 10809
   - å…¶ä»–: 1080, 8080, 8118, 9050

å¦‚æœè¿è¡Œ Clash ç­‰ä»£ç†è½¯ä»¶ï¼Œç¨‹åºä¼šè‡ªåŠ¨ä½¿ç”¨ `http://127.0.0.1:7890` æ— éœ€æ‰‹åŠ¨é…ç½®ã€‚

**ä»£ç è´¨é‡ï¼š**

- ruff: All checks passed!
- pyright: 0 errors, 0 warnings
- pytest: 490 passed, 8 skippedï¼ˆæ–°å¢ 6 ä¸ªä»£ç†æ£€æµ‹æµ‹è¯•ï¼‰
